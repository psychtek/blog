---
title: PCA on US Nutrition
author: Aaron Willcox
date: '2019-08-09'
slug: pca-on-us-nutrition
categories:
  - R
tags:
  - PCA
  - R Markdown
subtitle: ''
summary: ''
authors: []
lastmod: '2019-08-09T11:00:18+10:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
fig_width: 12
---

A quick walk through of running a PCA on US nutrition and the use of a couple of different packages in R, to display
information graphically. 

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(corrplot)
library(cowplot)
library(hrbrthemes)
```

#### Information

The following dataset froms from the Nutrient database in the United States

This is from the now outdated SR27. It is also created from the full database. The "abbreviated file" in SR28 is more up to date than this data and contains more nutrients than we provide here. See https://data.world/awram/food-nutritional-values

The columns in US RDA are created using data from Dietary Reference Intakes: The Essential Guide to Nutrient Requirements available from the National Academies Press at http://www.nap.edu/catalog/11537.html

Data
Each record is for 100 grams.

The columns are mostly self-explanatory. The nutrient columns end with the units, so:

Nutrient_g is in grams
Nutrient_mg is in milligrams
Nutrient_mcg is in micrograms
Nutrient_USRDA is in percentage of US Recommended Daily Allows (e.g. 0.50 is 50%)
Note that not every available RDA value in the text was used. For instance, the US RDA for Iron varies significantly by age and sex, so I deemed it easier to just leave out RDA information for Iron.

```{r message=FALSE, warning=FALSE}
# data_df <- read.csv(file = "https://query.data.world/s/iwzl7xgiagpimb2ixfj4fkyztngxs7", stringsAsFactors = FALSE, header = TRUE)

#write.csv(data_df, file = "data/nutrian_df.csv") # write the dataframe to csv

data_df <- read_csv(file = "data/nutrian_df.csv")
```

#### Running a Principle Componant Analysis on the United States Dietry Reference Nutrient Database

The USRDA containts the same information as _mg so these are reduntant and can be removed. 

```{r}

data_df <- data_df %>% select(-contains("_USRDA"))

```


Catagorical Visualisation 

```{r message=FALSE, warning=FALSE,  fig.width=10, fig.height=12}

data_df$FoodGroup <- factor(data_df$FoodGroup, ordered = is.ordered(data_df$FoodGroup)) # coerce to factor

Foodgroup_cat <- data_df %>% # Group by the food group catagory and count the amont each one occurs
  group_by(FoodGroup) %>% 
  summarise(N = n()) %>% 
  arrange(N)


Foodgroup_cat$FoodGroup <- str_remove(Foodgroup_cat$FoodGroup, "Products") # Remove the word "products" from the list

ggplot(Foodgroup_cat) +
 aes(x = reorder(FoodGroup, -N), y = N) +
 geom_bar(stat = "identity") +
 coord_flip() +
  labs(title = "Toal Amount of Food Products",
       subtitle = "USDRA",
       x = "Products", 
       y = "Frequency") +
  theme_ft_rc()



```

#### Amount of sugar in grams associated with total energy (k/cals) for each food group

```{r fig.height=12, fig.width=10, message=FALSE, warning=FALSE}

ggplot(data_df) +
 aes(x = Sugar_g, y = Energy_kcal, fill = FoodGroup, colour = FoodGroup) +
 geom_point(size = 1L) +
 scale_fill_hue() +
 scale_color_hue() +
 labs(x = "Sugar in gram", y = "Energy in k/cals", title = "Amount of Energy from Sugar for each Food Group", subtitle = "Food Groups") +
  theme_ft_rc() +
 theme(legend.position = "none") +
 facet_wrap(vars(FoodGroup), scales = "free_x")

```
Beef, lamb, veal and game products tend to have very little sugar/energy. Theres a clustering of points in the beverages table 
and would assume this would be water or low sugar drinks. Considering this is a database of nutrients based on major food groups, we cant tease out the underlying specifics of the types of drinks or products. 


There is some skewness in the data and could do with some transforming but theres no guarentee that it will improve results. 
Here we will rescale and center the variables with a mean of 0 and a variance of 1. Then run a correlation matrix to visualise the results. 

```{r, fig.width=10, fig.height=12}

data_df[,9:31] <- sqrt(data_df[,9:31]) # sqrt transform 

data_df_rescale <- data_df %>% 
  select(9:31) %>% 
  scale(center = TRUE)

data_df_corr <- data_df %>% select(9:31)

data_corrr <- cor(data_df_corr)
 
corrplot(as.matrix(data_corrr), is.corr = FALSE, method = "square", type = "full")
```

Run a PCA with the default prcomp function in R and run a summary on the object then display a scree plot with eigen vectors:

```{r}


data_PCA <- prcomp(data_df_rescale)

# print(data_PCA) # Full PCA matrix

summary(data_PCA) 



plot(data_PCA, type = "l")

# data_PCA$rotation

```

The summary method describe the importance of the PCs. The first row describe again the standard deviation associated with each PC. The second row shows the proportion of the variance in the data explained by each component while the third row describe the cumulative proportion of explained variance. We can see there that the first two PCs accounts for more than 47% (0.31+0.16) of the variance of the data. The remaining 53% is shared across PC3 to PC23. 

From the plot we can see that factors load the most on PC1 and PC2. The Scree plot also shows us visualy where the components fall off after PC1 and PC2. Use the FactorMineR package to extract more detailed data howver, will use the first 5 components as these tend to load the most on the components (69%). 

```{r message=FALSE, warning=FALSE}
library(FactoMineR)

data_PCA_all <- PCA(data_df_rescale, ncp  = 2, graph = TRUE)

data_PCA_all$eig #eigen values, percent of varaince and cumulative percentage

data_PCA_all$var$coord # correlations betwewen variables and PCs

```



When variables correlate strongly together they all converge on the same component. A simple method to extract the results, for variables, from a PCA output is to use the function get_pca_var() __[factoextra package]__. This function provides a list of matrices containing all the results for the active variables (coordinates, correlation between variables and axes, squared cosine and contributions)

This provides a nicer toolset to work with and display the PCA data:

```{r message=FALSE, warning=FALSE}
library(factoextra)

# a more colourful visual representation of the variables and where they converge on a component. 
fviz_pca_var(data_PCA_all
             , col.var = "cos2"
             , gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
             , repel = TRUE) # Avoid text overlapping)


get_eig(data_PCA_all) # display the eigen values, dimensions and variance

fviz_eig(data_PCA_all) # screeplot

corrplot(data_PCA_all$var$cor, is.corr=FALSE) 

fviz_contrib(data_PCA_all, choice = "var", axes = 1:2, top = 10)


```


Finally, with the Ggforce package we are able to plot  multiple components from a PCA analysis against each other component:

```{r message=FALSE, warning=FALSE, fig.width=10, fig.height=10}
library(ggforce)


pca_grid <- as.data.frame(data_PCA$rotation)

# Since the first ttwo compomnents make up most of the variance explain will add the
# 5 to make up 77% of the components for this example


ggplot(pca_grid[,1:7], aes(x = .panel_x, y = .panel_y)) + 
  geom_point(alpha = 0.9, shape = 16, size = 0.5) + 
  geom_autodensity() +
  geom_density2d() +
  facet_matrix(vars(everything()), layer.diag = 2, layer.upper = 3, 
               grid.y.diag = FALSE)
```

