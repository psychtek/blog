[{"authors":["admin"],"categories":null,"content":"Recently returning from studying abroad at Maastricht University in the Netherlands. Currently finishing 3rd year Bachelor of Psychological Science with the view to do honors 2020. Competent critical thinking, problem solving, data and statistical analysis skills. Interests include data wrangling with R and research into neurodevelopmental disorders particularly adult ADHD.\n","date":1554595200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Recently returning from studying abroad at Maastricht University in the Netherlands. Currently finishing 3rd year Bachelor of Psychological Science with the view to do honors 2020. Competent critical thinking, problem solving, data and statistical analysis skills. Interests include data wrangling with R and research into neurodevelopmental disorders particularly adult ADHD.","tags":null,"title":"Aaron Willcox","type":"authors"},{"authors":null,"categories":null,"content":" Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":" Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":[],"categories":["R"],"content":"\rGlobal Mortality Rates\rThe following dataset is from the Tidy Tuesday https://github.com/rfordatascience/tidytuesday/tree/master/data/2018/2018-04-16.\nlibrary(tidyverse)\rlibrary(hrbrthemes) # custom dark theme from hrbrpackage\rglobal_mort \u0026lt;- read_csv(file = \u0026quot;data/global_mortality.csv\u0026quot;, col_names = TRUE) # import dataset into object\rglobal_mort$country \u0026lt;- as.factor(global_mort$country) # Change character to factors\rglobal_mort$country_code \u0026lt;- as.factor(global_mort$country_code)\rglobal_mort$year \u0026lt;- as.factor(global_mort$year)\r\rGraphical Display of mortality rates in Australia from 1990 to 2016\rdf \u0026lt;- global_mort %\u0026gt;% group_by(country, year) %\u0026gt;% pivot_longer(cols = c(4:35)) df$name \u0026lt;- factor(df$name)\rdf %\u0026gt;% filter(\u0026quot;Australia\u0026quot; %in% country) %\u0026gt;% #filter(\u0026quot;Alcohol disorders (%)\u0026quot; == name) %\u0026gt;% #top_n(-15) %\u0026gt;% ggplot(aes(x = year, y = value, group = name)) +\rgeom_line(aes(color = name), size = 1) +\rlabs(x = \u0026quot;Year\u0026quot;, y = \u0026quot;Percentage (%)\u0026quot;, title = \u0026quot;Australian Mortality Rates\u0026quot;, subtitle = \u0026quot;1990 to 2016\u0026quot;) +\rtheme_ft_rc() +\rtheme(axis.text.x = element_text(size=10, angle=45)) +\rscale_y_percent()\r# ggplotly(p)\rdf %\u0026gt;% filter(\u0026quot;Australia\u0026quot; %in% country) %\u0026gt;% group_by(year, name) %\u0026gt;% filter(name == \u0026quot;Alcohol disorders (%)\u0026quot;)\r## # A tibble: 27 x 5\r## # Groups: year, name [27]\r## country country_code year name value\r## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 Australia AUS 1990 Alcohol disorders (%) 0.216\r## 2 Australia AUS 1991 Alcohol disorders (%) 0.215\r## 3 Australia AUS 1992 Alcohol disorders (%) 0.213\r## 4 Australia AUS 1993 Alcohol disorders (%) 0.216\r## 5 Australia AUS 1994 Alcohol disorders (%) 0.218\r## 6 Australia AUS 1995 Alcohol disorders (%) 0.225\r## 7 Australia AUS 1996 Alcohol disorders (%) 0.225\r## 8 Australia AUS 1997 Alcohol disorders (%) 0.232\r## 9 Australia AUS 1998 Alcohol disorders (%) 0.234\r## 10 Australia AUS 1999 Alcohol disorders (%) 0.244\r## # ... with 17 more rows\rAustralia \u0026lt;- global_mort %\u0026gt;% group_by(country, year) %\u0026gt;% arrange(year) %\u0026gt;% filter(country == \u0026quot;Australia\u0026quot;)\rggplot(Australia) +\raes(x = year, weight = `Cardiovascular diseases (%)`) +\rgeom_bar(fill = ft_cols$blue) +\rlabs(x = \u0026quot;\u0026quot;, y = \u0026quot;Amount %\u0026quot;, title = \u0026quot;Cardiovascular Disease in Australia\u0026quot;, subtitle = \u0026quot;1990 to 2016\u0026quot;) +\rtheme_ft_rc()\r# Drug Related Deaths in Australia\rggplot(Australia) +\raes(x = year, weight = `Drug disorders (%)`) +\rgeom_bar(fill = ft_cols$blue) +\rlabs(x = \u0026quot;\u0026quot;, y = \u0026quot;Amount %\u0026quot;, title = \u0026quot;Drug Related Deaths in Australia\u0026quot;, subtitle = \u0026quot;1990 to 2016\u0026quot;) +\rtheme_ft_rc()\rggplot(Australia) +\raes(x = year, weight = `Suicide (%)`) +\rgeom_bar(fill = ft_cols$blue) +\rlabs(x = \u0026quot;\u0026quot;, y = \u0026quot;Amount %\u0026quot;, title = \u0026quot;Suicides in Australia\u0026quot;, subtitle = \u0026quot;1990 to 2016\u0026quot;) +\rtheme_ft_rc()\rggplot(Australia) +\raes(x = year, weight = `Alcohol disorders (%)` ) +\rgeom_bar(fill = ft_cols$blue) +\rlabs(x = \u0026quot;\u0026quot;, y = \u0026quot;Amount %\u0026quot;, title = \u0026quot;Alochol Use in Australia\u0026quot;, subtitle = \u0026quot;1990 to 2016\u0026quot;) +\rtheme_ft_rc()\r\r","date":1566345600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566348584,"objectID":"be476443bd77c558cfca2250288c00fc","permalink":"/post/global-mortality-rates/","publishdate":"2019-08-21T00:00:00Z","relpermalink":"/post/global-mortality-rates/","section":"post","summary":"Global Mortality Rates\rThe following dataset is from the Tidy Tuesday https://github.com/rfordatascience/tidytuesday/tree/master/data/2018/2018-04-16.\nlibrary(tidyverse)\rlibrary(hrbrthemes) # custom dark theme from hrbrpackage\rglobal_mort \u0026lt;- read_csv(file = \u0026quot;data/global_mortality.csv\u0026quot;, col_names = TRUE) # import dataset into object\rglobal_mort$country \u0026lt;- as.factor(global_mort$country) # Change character to factors\rglobal_mort$country_code \u0026lt;- as.factor(global_mort$country_code)\rglobal_mort$year \u0026lt;- as.factor(global_mort$year)\r\rGraphical Display of mortality rates in Australia from 1990 to 2016\rdf \u0026lt;- global_mort %\u0026gt;% group_by(country, year) %\u0026gt;% pivot_longer(cols = c(4:35)) df$name \u0026lt;- factor(df$name)\rdf %\u0026gt;% filter(\u0026quot;Australia\u0026quot; %in% country) %\u0026gt;% #filter(\u0026quot;Alcohol disorders (%)\u0026quot; == name) %\u0026gt;% #top_n(-15) %\u0026gt;% ggplot(aes(x = year, y = value, group = name)) +\rgeom_line(aes(color = name), size = 1) +\rlabs(x = \u0026quot;Year\u0026quot;, y = \u0026quot;Percentage (%)\u0026quot;, title = \u0026quot;Australian Mortality Rates\u0026quot;, subtitle = \u0026quot;1990 to 2016\u0026quot;) +\rtheme_ft_rc() +\rtheme(axis.","tags":["R Markdown"],"title":"Global Mortality Rates","type":"post"},{"authors":[],"categories":["R"],"content":"\r\r\r\r\r\r\rThis is the second part of the expriment on Pattern Separation. This processes the participants hits and misses into the induced negative or neutral group and displays some results.\nImport\rRaw CSV files with all IAPS database and images to be used in each task imported into an object.\nraw_df \u0026lt;- read_csv(\u0026quot;data/ret_task.csv\u0026quot;\r, col_types = cols(CR = col_factor(levels = c(\u0026quot;same\u0026quot;, \u0026quot;different\u0026quot;))\r, Emotion = col_factor(levels = c(\u0026quot;negative\u0026quot;, \u0026quot;neutral\u0026quot;))\r, Sex = col_factor(levels = c(\u0026quot;male\u0026quot;, \u0026quot;female\u0026quot;))))\rraw_df$CorrectAnswer \u0026lt;- recode(raw_df$CorrectAnswer, a = \u0026quot;l\u0026quot;, l = \u0026quot;a\u0026quot;)\rraw_df$Stimulus1.RESP \u0026lt;- recode(raw_df$Stimulus1.RESP, a = \u0026quot;l\u0026quot;, l = \u0026quot;a\u0026quot;)\r# import tables RET_SEEN \u0026lt;- read_csv(\u0026quot;data/RET_SEEN.csv\u0026quot;)\rRET_UNSEEN_NEW \u0026lt;- read_csv(\u0026quot;data/RET_UNSEEN_NEW.csv\u0026quot;)\rRET_PS_a \u0026lt;- read_csv(\u0026quot;data/RET_PS_a.csv\u0026quot;)\r\rData Setup\r\r75 Negative Images\n\r75 Neutral Images\n\r\rGeneral d-prime score: p(hits|75) and then p(FA|75)\n\r\r\rSAME(A)\rDIFFERENT(L)\r\r\r\rNEW\rMISS(FA)\rHIT(CR)\r\rOLD\rMISS\rMISS\r\rSIMILAR\rHIT\rMISS\r\r\r\rCompute New Variables\rPattern separation scores were calculated by comparing the CorrectAnswer response to the actual Stimulus1.RESP and then allocated either a hit or miss where appropriate. Futher variables were then computed as a binary response of 1 for a hit or 0 for a miss.\nNegative and Neutral conditions were also computed as when a participant responded to a hit when a image is in the negative condition. Neutral was the compliment of this.\nraw_df \u0026lt;- raw_df %\u0026gt;% select_all() %\u0026gt;% mutate(\rPattern_Sep = case_when(\rCorrectAnswer == Stimulus1.RESP \u0026amp; CorrectAnswer == \u0026quot;a\u0026quot; ~ \u0026quot;Hit\u0026quot;, # Condition checks to match correct answer to CorrectAnswer == Stimulus1.RESP \u0026amp; CorrectAnswer == \u0026quot;l\u0026quot; ~ \u0026quot;Hit\u0026quot;, # the participants response. Labelled as \u0026quot;hits\u0026quot;\rCorrectAnswer != Stimulus1.RESP \u0026amp; CorrectAnswer == \u0026quot;l\u0026quot; ~ \u0026quot;Miss\u0026quot;, # and \u0026quot;miss\u0026quot; for easy identifying. CorrectAnswer != Stimulus1.RESP \u0026amp; CorrectAnswer == \u0026quot;a\u0026quot; ~ \u0026quot;Miss\u0026quot;,\rTRUE ~ \u0026quot;\u0026quot;)) %\u0026gt;% mutate(\rScore = case_when(\rPattern_Sep == \u0026quot;Hit\u0026quot; ~ 1, # A column of hits and misses coded 1 for hit and 0 for miss\rPattern_Sep == \u0026quot;Miss\u0026quot; ~ 0\r)\r) %\u0026gt;% mutate(\rTotal_Hits = factor(case_when( # total counts for hits and misses\rScore == 1 ~ 1,\rScore == 0 ~ 0\r)),\rTotal_Miss = factor(case_when(\rScore == 0 ~ 1,\rScore == 1 ~ 0\r))\r) %\u0026gt;% mutate(Hit_similar = factor(ifelse(CorrectAnswer %in% c(\u0026quot;a\u0026quot;) \u0026amp; # These columns count the appropriate hits and misses\rStimulus1.RESP == \u0026quot;a\u0026quot;, 1, 0)), # for each emotional condition. Negative_Hit = factor(ifelse(Emotion %in% c(\u0026quot;negative\u0026quot;) \u0026amp;\rPattern_Sep == \u0026quot;Hit\u0026quot;, 1, 0)),\rNegative_Miss = factor(ifelse(Emotion %in% c(\u0026quot;negative\u0026quot;) \u0026amp;\rPattern_Sep == \u0026quot;Miss\u0026quot;, 1, 0)),\rNeutral_Hit = factor(ifelse(Emotion %in% c(\u0026quot;neutral\u0026quot;) \u0026amp;\rPattern_Sep == \u0026quot;Hit\u0026quot;, 1, 0)),\rNeutral_Miss = factor(ifelse(Emotion %in% c(\u0026quot;neutral\u0026quot;) \u0026amp;\rPattern_Sep == \u0026quot;Miss\u0026quot;, 1, 0)))\rraw_df$Picture \u0026lt;- str_remove(raw_df$Picture, \u0026quot;.jpg\u0026quot;) #remove the jpg extention\r# check the column picture number and compare to the originally coded\r# tasks use to setup the experiment. raw_df \u0026lt;- raw_df %\u0026gt;% mutate(\rcoding = case_when(\rPicture %in% RET_PS_a$V1 ~ \u0026quot;SIMILAR\u0026quot;, Picture %in% RET_UNSEEN_NEW$nr ~ \u0026quot;NEW\u0026quot;, Picture %in% RET_SEEN$nr ~ \u0026quot;OLD\u0026quot;,\rTRUE ~ \u0026quot;\u0026quot;))\r# Added pattern separation counts similar to Stark(2013)\rraw_df \u0026lt;- raw_df %\u0026gt;% mutate(pshits = ifelse(coding %in% c(\u0026quot;SIMILAR\u0026quot;) \u0026amp; Stimulus1.RESP == \u0026quot;a\u0026quot;, 1, 0),\rpsmiss = ifelse(coding %in% c(\u0026quot;SIMILAR\u0026quot;) \u0026amp; Stimulus1.RESP == \u0026quot;l\u0026quot;, 1, 0),\rpscr = ifelse(coding %in% c(\u0026quot;NEW\u0026quot;) \u0026amp; Stimulus1.RESP == \u0026quot;l\u0026quot;, 1, 0),\rpsfa = ifelse(coding %in% c(\u0026quot;NEW\u0026quot;) \u0026amp; Stimulus1.RESP == \u0026quot;a\u0026quot;, 1, 0))\r\r\rGrouping Variables and Joining To Long Format:\rTemporary tables are then created per subject based on hits and misses.\na \u0026lt;- raw_df %\u0026gt;% group_by(Subject, Neutral_Hit) %\u0026gt;% tally() %\u0026gt;% filter(Neutral_Hit == 1) %\u0026gt;% select(n) %\u0026gt;% rename(Neutral_hits = n) b \u0026lt;- raw_df %\u0026gt;% group_by(Subject, Neutral_Miss) %\u0026gt;% tally() %\u0026gt;% filter(Neutral_Miss == 1) %\u0026gt;% select(n) %\u0026gt;% rename(Neutral_miss = n) c \u0026lt;- raw_df %\u0026gt;% group_by(Subject, Negative_Hit) %\u0026gt;% tally() %\u0026gt;% filter(Negative_Hit == 1) %\u0026gt;% select(n) %\u0026gt;% rename(Negative_hits = n) d \u0026lt;- raw_df %\u0026gt;% group_by(Subject, Negative_Miss) %\u0026gt;% tally() %\u0026gt;% filter(Negative_Miss == 1) %\u0026gt;% select(n) %\u0026gt;% rename(Negative_miss = n) e \u0026lt;- full_join(a, b)\rf \u0026lt;- full_join(c, d)\rg \u0026lt;- full_join(e, f)\rh \u0026lt;- raw_df %\u0026gt;% group_by(Subject) %\u0026gt;% filter(Total_Hits == 1) %\u0026gt;% tally() %\u0026gt;% rename(\u0026quot;Total_hits\u0026quot; = n)\ri \u0026lt;- raw_df %\u0026gt;% group_by(Subject) %\u0026gt;% filter(Total_Miss == 1) %\u0026gt;% tally() %\u0026gt;% rename(\u0026quot;Total_miss\u0026quot; = n)\rj \u0026lt;- full_join(h, i)\rk \u0026lt;- full_join(g, j)\rl \u0026lt;- raw_df %\u0026gt;% select(Subject, Sex, Stimulus1.RT) %\u0026gt;% group_by(Subject, Sex) %\u0026gt;% summarise(MeanRT = mean(Stimulus1.RT), )\rRet_task_a \u0026lt;- full_join(l, k)\rm \u0026lt;- raw_df %\u0026gt;% select(Subject, Sex, Emotion, Stimulus1.RT) %\u0026gt;% filter(Emotion == \u0026quot;negative\u0026quot;) %\u0026gt;% group_by(Subject, Sex) %\u0026gt;% summarise(Neg_RT = mean(Stimulus1.RT))\rn \u0026lt;- raw_df %\u0026gt;% select(Subject, Sex, Emotion, Stimulus1.RT) %\u0026gt;% filter(Emotion == \u0026quot;neutral\u0026quot;) %\u0026gt;% group_by(Subject, Sex) %\u0026gt;% summarise(Neut_RT = mean(Stimulus1.RT))\r# ---\rd1 \u0026lt;- raw_df %\u0026gt;% group_by(Subject) %\u0026gt;% filter(Emotion == \u0026quot;negative\u0026quot; \u0026amp; Hit_similar == \u0026quot;1\u0026quot;) %\u0026gt;%\rtally() %\u0026gt;%\rrename(\u0026quot;Neg_Sim_Hit\u0026quot; = n)\rd2 \u0026lt;- raw_df %\u0026gt;% group_by(Subject) %\u0026gt;% filter(Emotion == \u0026quot;neutral\u0026quot; \u0026amp; Hit_similar == \u0026quot;1\u0026quot;) %\u0026gt;%\rtally() %\u0026gt;%\rrename(\u0026quot;Neut_Sim_Hit\u0026quot; = n)\rRet_task_c \u0026lt;- full_join(d1, d2)\r# ---\rRet_task_b \u0026lt;- full_join(m, n) Ret_task_d \u0026lt;- full_join(Ret_task_b, Ret_task_c)\rRet_task_df_temp \u0026lt;- full_join(Ret_task_a, Ret_task_d) # temp join of data tables\rpattern_sep_scores \u0026lt;- raw_df %\u0026gt;% group_by(Subject, Sex) %\u0026gt;% summarise(n_hits = sum(pshits)\r, n_miss = sum(psmiss)\r, n_cr = sum(pscr)\r, n_fa = sum(psfa)) %\u0026gt;% mutate(n_hits = replace(n_hits, which(is.na(n_hits)), 0)) %\u0026gt;% mutate(n_miss = replace(n_miss, which(is.na(n_miss)), 0)) %\u0026gt;% mutate(n_cr = replace(n_cr, which(is.na(n_cr)), 0)) %\u0026gt;% mutate(n_fa = replace(n_fa, which(is.na(n_fa)), 0))\rpattern_sep_scores \u0026lt;- pattern_sep_scores %\u0026gt;% mutate(Perc_correct = (n_hits + n_cr)/(n_hits + n_miss + n_fa +n_cr)\r, Dprime = (n_hits/(n_hits + n_miss)-(n_fa/(n_fa + n_cr))))\rRet_task_df_join \u0026lt;- full_join(Ret_task_df_temp, pattern_sep_scores)\rdatatable(Ret_task_df_join)\r\r{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\"],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,50,51,52,53,54,55,56,57,58,59],[\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"male\",\"female\",\"female\",\"female\",\"female\",\"female\",\"male\",\"female\",\"female\",\"female\",\"female\",\"male\",\"female\",\"male\",\"male\",\"male\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"male\",\"female\",\"male\",\"female\",\"male\",\"male\",\"female\",\"female\",\"male\",\"female\",\"male\",\"female\",\"female\",\"male\",\"female\",\"female\",\"female\",\"male\"],[0,1298.66666666667,10.52,1525.94666666667,1213.78,1799.62,1119.41333333333,1217.12,744.86,1304.34,1294.08666666667,1481.85333333333,1198.86666666667,1226.98,1439.39333333333,1254.48666666667,1455.61333333333,1785.65333333333,1252.78,1431.15333333333,1131.36,1609.92666666667,1436.04666666667,1581.80666666667,2077.56,1302.44666666667,1296.04,1613,1530.57333333333,1603.76666666667,1780.80666666667,1547.81333333333,1611.20666666667,1794.96,1505.66666666667,1487.03333333333,1520.32666666667,1531.78666666667,954.386666666667,1763.06,1261.64,1394.30666666667,1757.8,1673.36666666667,1483.72666666667,1496.02,1354.52666666667,1414.34,1669.83333333333,1150.92,1635.57333333333,1553.92666666667,1379.62,2022.31333333333,1032.76666666667,1129.14666666667,1311.34,1954.56666666667],[null,9,1,53,63,49,69,55,38,60,63,57,59,58,65,55,68,56,65,61,58,59,67,67,58,62,57,64,64,62,65,64,54,62,61,65,68,64,65,56,57,63,65,63,58,67,60,50,58,52,69,65,58,52,44,64,53,50],[null,66,null,22,12,19,6,20,7,15,12,17,16,16,9,19,7,19,10,14,17,16,8,8,14,13,18,11,11,11,9,11,21,13,14,10,7,11,10,19,18,12,8,12,17,8,15,25,17,23,6,10,17,22,8,11,22,24],[null,9,null,57,63,46,69,45,33,53,65,62,55,57,65,52,64,55,64,62,56,66,68,58,55,52,52,64,65,67,66,61,56,60,59,53,66,61,58,67,63,59,59,62,64,65,67,61,62,52,62,59,65,46,43,68,64,46],[null,66,null,18,12,18,6,30,11,22,10,13,20,18,10,23,11,20,10,13,19,9,6,16,18,23,23,11,10,7,7,14,19,15,16,22,9,14,17,8,12,16,10,13,11,10,8,14,13,23,12,15,10,28,9,7,11,27],[null,18,1,110,126,95,138,100,71,113,128,119,114,115,130,107,132,111,129,123,114,125,135,125,113,114,109,128,129,129,131,125,110,122,120,118,134,125,123,123,120,122,124,125,122,132,127,111,120,104,131,124,123,98,87,132,117,96],[null,132,null,40,24,37,12,50,18,37,22,30,36,34,19,42,18,39,20,27,36,25,14,24,32,36,41,22,21,18,16,25,40,28,30,32,16,25,27,27,30,28,18,25,28,18,23,39,30,46,18,25,27,50,17,18,33,51],[0,1436.54666666667,0,1542.25333333333,1331.24,1801.16,1180.41333333333,1335.93333333333,720.533333333333,1379.02666666667,1435.82666666667,1710.89333333333,1275.65333333333,1303.58666666667,1578.14666666667,1300.25333333333,1567.52,1881.14666666667,1306.61333333333,1572.25333333333,1182.74666666667,1662.46666666667,1443.50666666667,1752.22666666667,2146.66666666667,1371.09333333333,1356.54666666667,1672.26666666667,1603.96,1743.04,2002.08,1741.22666666667,1787,1894.76,1682.26666666667,1606.81333333333,1728.26666666667,1612.97333333333,1026.22666666667,1978.97333333333,1293.29333333333,1407.12,1848.41333333333,1843.32,1587.05333333333,1620.12,1481.8,1449.64,1702.42666666667,1286.36,1728.53333333333,1743.64,1422.98666666667,2056.34666666667,1141.70666666667,1175.32,1411.66666666667,1985.09333333333],[0,1160.78666666667,21.04,1509.64,1096.32,1798.08,1058.41333333333,1098.30666666667,769.186666666667,1229.65333333333,1152.34666666667,1252.81333333333,1122.08,1150.37333333333,1300.64,1208.72,1343.70666666667,1690.16,1198.94666666667,1290.05333333333,1079.97333333333,1557.38666666667,1428.58666666667,1411.38666666667,2008.45333333333,1233.8,1235.53333333333,1553.73333333333,1457.18666666667,1464.49333333333,1559.53333333333,1354.4,1435.41333333333,1695.16,1329.06666666667,1367.25333333333,1312.38666666667,1450.6,882.546666666667,1547.14666666667,1229.98666666667,1381.49333333333,1667.18666666667,1503.41333333333,1380.4,1371.92,1227.25333333333,1379.04,1637.24,1015.48,1542.61333333333,1364.21333333333,1336.25333333333,1988.28,923.826666666667,1082.97333333333,1211.01333333333,1924.04],[null,1,null,15,21,16,23,15,3,15,20,18,21,14,22,19,18,22,24,25,16,18,23,20,20,21,22,19,21,22,22,21,8,17,17,12,23,24,23,22,17,19,21,20,23,22,24,17,14,22,18,21,23,21,11,22,20,11],[null,5,null,12,21,11,25,15,10,13,17,19,19,14,19,19,23,20,20,23,15,15,20,22,22,18,18,18,23,21,21,21,8,16,20,20,21,21,21,15,14,19,24,20,22,23,17,9,8,17,22,20,15,19,10,19,11,11],[0,40,0,13,12,0,8,21,0,9,9,16,20,10,6,21,9,20,0,19,12,7,6,11,0,19,22,6,12,0,9,13,6,5,14,12,7,15,16,12,10,13,0,13,18,11,11,11,2,28,0,11,13,27,0,8,12,0],[0,10,0,37,38,0,42,29,0,41,41,34,30,40,44,29,41,30,0,31,38,43,44,39,0,31,28,44,38,0,41,37,44,45,36,38,43,35,34,38,40,37,0,37,32,39,39,39,48,22,0,39,37,23,0,42,38,0],[0,2,0,46,46,0,48,41,0,44,50,48,44,0,45,0,50,39,49,44,45,49,0,44,0,44,41,47,47,0,0,46,50,44,47,48,47,45,45,48,49,47,0,48,45,48,47,46,50,43,50,0,48,0,0,49,48,46],[0,48,0,4,4,0,2,9,0,6,0,2,6,0,5,0,0,11,1,6,5,1,0,6,0,6,9,3,3,0,0,4,0,6,3,2,3,5,5,2,1,3,0,2,5,2,3,4,0,7,0,0,2,0,0,1,2,4],[null,0.42,null,0.59,0.58,null,0.56,0.62,null,0.53,0.59,0.64,0.64,0.2,0.51,0.42,0.59,0.59,0.98,0.63,0.57,0.56,0.12,0.55,null,0.63,0.63,0.53,0.59,null,0.18,0.59,0.56,0.49,0.61,0.6,0.54,0.6,0.61,0.6,0.59,0.6,null,0.61,0.63,0.59,0.58,0.57,0.52,0.71,1,0.22,0.61,0.54,null,0.57,0.6,0.92],[null,-0.16,null,0.18,0.16,null,0.12,0.24,null,0.06,0.18,0.28,0.28,null,0.02,null,0.18,0.18,null,0.26,0.14,0.12,null,0.1,null,0.26,0.26,0.06,0.18,null,null,0.18,0.12,-0.02,0.22,0.2,0.08,0.2,0.22,0.2,0.18,0.2,null,0.22,0.26,0.18,0.16,0.14,0.04,0.42,null,null,0.22,null,null,0.14,0.2,null]],\"container\":\"\\n \\n \\n  \\n Subject\\n Sex\\n MeanRT\\n Neutral_hits\\n Neutral_miss\\n Negative_hits\\n Negative_miss\\n Total_hits\\n Total_miss\\n Neg_RT\\n Neut_RT\\n Neg_Sim_Hit\\n Neut_Sim_Hit\\n n_hits\\n n_miss\\n n_cr\\n n_fa\\n Perc_correct\\n Dprime\\n \\n \\n\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\rValidation Task Data\rValidation database imported into an object\nval_task \u0026lt;- read_csv(file = \u0026quot;data/val_task.csv\u0026quot;)\rA table is created by grouping by each subject and then a new variable is computed for each emotion score dimension.\rThere is also response times for each image but wont be using those for this analysis.\nval_df \u0026lt;- val_task %\u0026gt;% group_by(Subject) %\u0026gt;% summarise(Arousal = mean(arousal.RESP), Valence = mean(valence.RESP), Dominance = mean(dominance.RESP))\r\rFull join of both tasks to one dataframe in wide format\rval_df$Subject \u0026lt;- as.factor(val_df$Subject)\rRet_task_df_join$Subject \u0026lt;- as.factor(Ret_task_df_join$Subject)\rgroup_39_wide \u0026lt;- full_join(Ret_task_df_join, val_df) # Final data table with all computed results\rdatatable(group_39_wide)\r\r{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\"],[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\"],[\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"male\",\"female\",\"female\",\"female\",\"female\",\"female\",\"male\",\"female\",\"female\",\"female\",\"female\",\"male\",\"female\",\"male\",\"male\",\"male\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"male\",\"female\",\"male\",\"female\",\"male\",\"male\",\"female\",\"female\",\"male\",\"female\",\"male\",\"female\",\"female\",\"male\",\"female\",\"female\",\"female\",\"male\"],[0,1298.66666666667,10.52,1525.94666666667,1213.78,1799.62,1119.41333333333,1217.12,744.86,1304.34,1294.08666666667,1481.85333333333,1198.86666666667,1226.98,1439.39333333333,1254.48666666667,1455.61333333333,1785.65333333333,1252.78,1431.15333333333,1131.36,1609.92666666667,1436.04666666667,1581.80666666667,2077.56,1302.44666666667,1296.04,1613,1530.57333333333,1603.76666666667,1780.80666666667,1547.81333333333,1611.20666666667,1794.96,1505.66666666667,1487.03333333333,1520.32666666667,1531.78666666667,954.386666666667,1763.06,1261.64,1394.30666666667,1757.8,1673.36666666667,1483.72666666667,1496.02,1354.52666666667,1414.34,1669.83333333333,1150.92,1635.57333333333,1553.92666666667,1379.62,2022.31333333333,1032.76666666667,1129.14666666667,1311.34,1954.56666666667],[null,9,1,53,63,49,69,55,38,60,63,57,59,58,65,55,68,56,65,61,58,59,67,67,58,62,57,64,64,62,65,64,54,62,61,65,68,64,65,56,57,63,65,63,58,67,60,50,58,52,69,65,58,52,44,64,53,50],[null,66,null,22,12,19,6,20,7,15,12,17,16,16,9,19,7,19,10,14,17,16,8,8,14,13,18,11,11,11,9,11,21,13,14,10,7,11,10,19,18,12,8,12,17,8,15,25,17,23,6,10,17,22,8,11,22,24],[null,9,null,57,63,46,69,45,33,53,65,62,55,57,65,52,64,55,64,62,56,66,68,58,55,52,52,64,65,67,66,61,56,60,59,53,66,61,58,67,63,59,59,62,64,65,67,61,62,52,62,59,65,46,43,68,64,46],[null,66,null,18,12,18,6,30,11,22,10,13,20,18,10,23,11,20,10,13,19,9,6,16,18,23,23,11,10,7,7,14,19,15,16,22,9,14,17,8,12,16,10,13,11,10,8,14,13,23,12,15,10,28,9,7,11,27],[null,18,1,110,126,95,138,100,71,113,128,119,114,115,130,107,132,111,129,123,114,125,135,125,113,114,109,128,129,129,131,125,110,122,120,118,134,125,123,123,120,122,124,125,122,132,127,111,120,104,131,124,123,98,87,132,117,96],[null,132,null,40,24,37,12,50,18,37,22,30,36,34,19,42,18,39,20,27,36,25,14,24,32,36,41,22,21,18,16,25,40,28,30,32,16,25,27,27,30,28,18,25,28,18,23,39,30,46,18,25,27,50,17,18,33,51],[0,1436.54666666667,0,1542.25333333333,1331.24,1801.16,1180.41333333333,1335.93333333333,720.533333333333,1379.02666666667,1435.82666666667,1710.89333333333,1275.65333333333,1303.58666666667,1578.14666666667,1300.25333333333,1567.52,1881.14666666667,1306.61333333333,1572.25333333333,1182.74666666667,1662.46666666667,1443.50666666667,1752.22666666667,2146.66666666667,1371.09333333333,1356.54666666667,1672.26666666667,1603.96,1743.04,2002.08,1741.22666666667,1787,1894.76,1682.26666666667,1606.81333333333,1728.26666666667,1612.97333333333,1026.22666666667,1978.97333333333,1293.29333333333,1407.12,1848.41333333333,1843.32,1587.05333333333,1620.12,1481.8,1449.64,1702.42666666667,1286.36,1728.53333333333,1743.64,1422.98666666667,2056.34666666667,1141.70666666667,1175.32,1411.66666666667,1985.09333333333],[0,1160.78666666667,21.04,1509.64,1096.32,1798.08,1058.41333333333,1098.30666666667,769.186666666667,1229.65333333333,1152.34666666667,1252.81333333333,1122.08,1150.37333333333,1300.64,1208.72,1343.70666666667,1690.16,1198.94666666667,1290.05333333333,1079.97333333333,1557.38666666667,1428.58666666667,1411.38666666667,2008.45333333333,1233.8,1235.53333333333,1553.73333333333,1457.18666666667,1464.49333333333,1559.53333333333,1354.4,1435.41333333333,1695.16,1329.06666666667,1367.25333333333,1312.38666666667,1450.6,882.546666666667,1547.14666666667,1229.98666666667,1381.49333333333,1667.18666666667,1503.41333333333,1380.4,1371.92,1227.25333333333,1379.04,1637.24,1015.48,1542.61333333333,1364.21333333333,1336.25333333333,1988.28,923.826666666667,1082.97333333333,1211.01333333333,1924.04],[null,1,null,15,21,16,23,15,3,15,20,18,21,14,22,19,18,22,24,25,16,18,23,20,20,21,22,19,21,22,22,21,8,17,17,12,23,24,23,22,17,19,21,20,23,22,24,17,14,22,18,21,23,21,11,22,20,11],[null,5,null,12,21,11,25,15,10,13,17,19,19,14,19,19,23,20,20,23,15,15,20,22,22,18,18,18,23,21,21,21,8,16,20,20,21,21,21,15,14,19,24,20,22,23,17,9,8,17,22,20,15,19,10,19,11,11],[0,40,0,13,12,0,8,21,0,9,9,16,20,10,6,21,9,20,0,19,12,7,6,11,0,19,22,6,12,0,9,13,6,5,14,12,7,15,16,12,10,13,0,13,18,11,11,11,2,28,0,11,13,27,0,8,12,0],[0,10,0,37,38,0,42,29,0,41,41,34,30,40,44,29,41,30,0,31,38,43,44,39,0,31,28,44,38,0,41,37,44,45,36,38,43,35,34,38,40,37,0,37,32,39,39,39,48,22,0,39,37,23,0,42,38,0],[0,2,0,46,46,0,48,41,0,44,50,48,44,0,45,0,50,39,49,44,45,49,0,44,0,44,41,47,47,0,0,46,50,44,47,48,47,45,45,48,49,47,0,48,45,48,47,46,50,43,50,0,48,0,0,49,48,46],[0,48,0,4,4,0,2,9,0,6,0,2,6,0,5,0,0,11,1,6,5,1,0,6,0,6,9,3,3,0,0,4,0,6,3,2,3,5,5,2,1,3,0,2,5,2,3,4,0,7,0,0,2,0,0,1,2,4],[null,0.42,null,0.59,0.58,null,0.56,0.62,null,0.53,0.59,0.64,0.64,0.2,0.51,0.42,0.59,0.59,0.98,0.63,0.57,0.56,0.12,0.55,null,0.63,0.63,0.53,0.59,null,0.18,0.59,0.56,0.49,0.61,0.6,0.54,0.6,0.61,0.6,0.59,0.6,null,0.61,0.63,0.59,0.58,0.57,0.52,0.71,1,0.22,0.61,0.54,null,0.57,0.6,0.92],[null,-0.16,null,0.18,0.16,null,0.12,0.24,null,0.06,0.18,0.28,0.28,null,0.02,null,0.18,0.18,null,0.26,0.14,0.12,null,0.1,null,0.26,0.26,0.06,0.18,null,null,0.18,0.12,-0.02,0.22,0.2,0.08,0.2,0.22,0.2,0.18,0.2,null,0.22,0.26,0.18,0.16,0.14,0.04,0.42,null,null,0.22,null,null,0.14,0.2,null],[null,4.63,null,5.36,3.98,5.1,4.67,5.41,5.21,4.3,4.18,2.21,4.52,2.76,4.27,5.58,3.88,4.29,4.23,3.92,2.36,3.94,4.68,3.66,4.98,5.29,5.07,4.36,4.98,4.05,4.26,3.66,4.87,1.73,2.51,5.18,4.7,4.01,4.27,4.46,4.99,4.64,4.05,3.12,3.85,4.18,4.99,3.78,5.25,3.42,4.43,4.79,4.82,2.63,5.7,1.09,6.78,4.48],[null,null,null,3.93,3.9,4.59,4.22,4.43,4.29,5.2,4.93,4.49,4.2,6.66,3.35,4.08,4.05,5.2,4.9,5.91,5.45,4.38,3.93,4.74,4.77,3.71,4.49,4.31,4.61,4.98,4.18,4.68,3.99,3.9,4.7,3.91,5.17,5.98,4.13,4.38,3.55,4.38,4.63,4.21,4.55,4.34,4.84,5.03,4.08,4.73,4.89,4.86,4.77,6,3.96,5,3.4,3.83],[null,null,null,4.17,4.97,5.63,5.59,4.93,5.19,5.52,4.86,7.84,5.29,7.58,4.98,4.31,5.77,5.59,5.79,5.53,5.35,5.27,4.58,5.83,5.08,4.4,4.86,5.09,4.92,6.2,6.89,6.23,4.89,5.09,5.11,4.87,5.04,7.03,5.76,6.57,6.76,4.97,5.2,3.29,5.62,6.52,5.27,6.12,3.85,5.15,5.84,5.45,5.67,6.78,5.26,8.76,3.99,4.94]],\"container\":\"\\n \\n \\n  \\n Subject\\n Sex\\n MeanRT\\n Neutral_hits\\n Neutral_miss\\n Negative_hits\\n Negative_miss\\n Total_hits\\n Total_miss\\n Neg_RT\\n Neut_RT\\n Neg_Sim_Hit\\n Neut_Sim_Hit\\n n_hits\\n n_miss\\n n_cr\\n n_fa\\n Perc_correct\\n Dprime\\n Arousal\\n Valence\\n Dominance\\n \\n \\n\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\rDescriptives\rmy_fun \u0026lt;- function(x, num_var){\rnum_var \u0026lt;- enquo(num_var)\rx %\u0026gt;%\rsummarize(avg = mean(!!num_var), n = n(), sd = sd(!!num_var), se = sd/sqrt(n))\r}\rmean_response_time \u0026lt;- group_39_wide %\u0026gt;%\rgroup_by(Sex) %\u0026gt;%\rmy_fun(MeanRT)\rneg_similar_hits \u0026lt;- group_39_wide %\u0026gt;%\rgroup_by(Sex) %\u0026gt;%\rna.omit() %\u0026gt;% my_fun(Neg_Sim_Hit)\rkable(mean_response_time) %\u0026gt;% kable_styling()\r\r\rSex\r\ravg\r\rn\r\rsd\r\rse\r\r\r\r\r\rmale\r\r1564.430\r\r14\r\r247.320\r\r66.09905\r\r\r\rfemale\r\r1352.464\r\r44\r\r389.461\r\r58.71346\r\r\r\r\rkable(neg_similar_hits) %\u0026gt;% kable_styling()\r\r\rSex\r\ravg\r\rn\r\rsd\r\rse\r\r\r\r\r\rmale\r\r19.44444\r\r9\r\r3.126944\r\r1.0423146\r\r\r\rfemale\r\r19.58065\r\r31\r\r3.801528\r\r0.6827745\r\r\r\r\r\rEmotion Scores\r# Gather variables and change to wide format\rret_long \u0026lt;- group_39_wide %\u0026gt;% gather(key, value, Valence, Arousal, Dominance) %\u0026gt;%\rselect(Subject, key, value, Sex) %\u0026gt;% rename(\u0026quot;Emotion\u0026quot; = key) %\u0026gt;% arrange(desc(Subject))\rggplot(data = ret_long) +\raes(x = value) +\rgeom_histogram(bins = 30, fill = \u0026quot;#1f78b4\u0026quot;) +\rlabs(title = \u0026quot;Distribution of Emotion Response Scores\u0026quot;,\rx = \u0026quot;Mean Scores\u0026quot;,\ry = \u0026quot;Ratings\u0026quot;,\rsubtitle = \u0026quot;IAPS Scores\u0026quot;) +\rtheme_cowplot() +\rfacet_wrap(vars(Emotion))\r\rEmotion Ratings from Negative Stimuli\r# Negative Emotion Scores\rval_task %\u0026gt;% filter(condition == \u0026quot;negative\u0026quot;) %\u0026gt;% na.omit() %\u0026gt;% group_by(Subject, Sex) %\u0026gt;% summarise(Arousal = mean(arousal.RESP)\r, Dominance = mean(dominance.RESP)\r, Valence = mean(valence.RESP)) %\u0026gt;% gather(key, value, Arousal, Dominance, Valence) %\u0026gt;% rename(\u0026quot;Emotion\u0026quot; = key) %\u0026gt;% ggplot(aes(x = value)) +\rgeom_histogram(bins = 20, fill = \u0026quot;#1f78b4\u0026quot;) +\rlabs(title = \u0026quot;Emotion Scores from Negative Stimuli\u0026quot;,\ry = \u0026quot;Response\u0026quot;,\rsubtitle = \u0026quot;Arousal, Dominance and Valence\u0026quot;) +\rtheme_cowplot() +\rfacet_wrap(vars(Emotion))\rAs expected, negative stimuli have a higher arousal rating and lower valence rating.\n\rEmotion Ratings from Neutral Stimuli\r# Neutral Emotion Scores\rval_task %\u0026gt;% filter(condition == \u0026quot;neutral\u0026quot;) %\u0026gt;% na.omit() %\u0026gt;% group_by(Subject, Sex) %\u0026gt;% summarise(Arousal = mean(arousal.RESP)\r, Dominance = mean(dominance.RESP)\r, Valence = mean(valence.RESP)) %\u0026gt;% gather(key, value, Arousal, Dominance, Valence) %\u0026gt;% rename(\u0026quot;Emotion\u0026quot; = key) %\u0026gt;% ggplot(aes(x = value)) +\rgeom_histogram(bins = 20, fill = \u0026quot;#1f78b4\u0026quot;) +\rlabs(title = \u0026quot;Emotion Scores from the Neutral Condition\u0026quot;,\rsubtitle = \u0026quot;Arousal, Dominance and Valence\u0026quot;) +\rtheme_cowplot() +\rfacet_wrap(vars(Emotion))\rThis is what we would expect. Neutral stimuli should have low arousal ratings and higher valence ratings.\n\rHistogram of Total Negative and Neutral Condition hits\rgroup_39_wide %\u0026gt;% gather(key, value, Neutral_hits, Negative_hits) %\u0026gt;% # change to long format\rselect(Subject, Sex, key, value) %\u0026gt;%\rna.omit() %\u0026gt;% ggplot(aes(x = value)) +\rgeom_histogram(bins = 22, fill = \u0026quot;#1f78b4\u0026quot;) +\rtheme_cowplot() +\rfacet_wrap(vars(key)) +\rgeom_vline(aes(xintercept = mean(value)), linetype = \u0026quot;dashed\u0026quot;) \r\rNegative Similar Hits (Male vs Females)\rThis is our overall indicator of if there is evidence of pattern separation performance. The ability to detect\ra image that was seen in the encoding task and recall if it they had seen it previously.\ngroup_39_wide %\u0026gt;% select(Sex, Neg_Sim_Hit, Subject) %\u0026gt;%\rna.omit() %\u0026gt;% ggplot(aes(x = Neg_Sim_Hit)) +\rgeom_histogram(bins = 22, fill = \u0026quot;#1f78b4\u0026quot;) +\rlabs(title = \u0026quot;Negative Similar Hits\u0026quot;,\rsubtitle = \u0026quot;Male and Females\u0026quot;) +\rtheme_cowplot() +\rfacet_wrap(vars(Sex)) +\rgeom_vline(data = na.omit(group_39_wide), aes(xintercept = mean(Neg_Sim_Hit)), linetype = \u0026quot;dashed\u0026quot;)\r\rNeutral Simiar Hits (Male vs Females)\rgroup_39_wide %\u0026gt;% select(Sex, Neut_Sim_Hit, Subject) %\u0026gt;%\rna.omit() %\u0026gt;% ggplot(aes(x = Neut_Sim_Hit)) +\rgeom_histogram(bins = 22, fill = \u0026quot;#1f78b4\u0026quot;) +\rlabs(title = \u0026quot;Neutral Similar Hits\u0026quot;,\rsubtitle = \u0026quot;Male and Females\u0026quot;) +\rtheme_cowplot() +\rfacet_wrap(vars(Sex)) +\rgeom_vline(data = na.omit(group_39_wide), aes(xintercept = mean(Neut_Sim_Hit)), linetype = \u0026quot;dashed\u0026quot;)\r\rValidated vs Fake Comparisons\rWe need to check if the altered images were eliciting a similar emotional response as to the\roriginal IAPS validated images. There should be no difference between dimensions specifically, arousal and valence. If there is a difference then we dont know if we are actually eliciting the same response from participants as we want to.\nI had already processed this file previous created a file with two groups. Group a is the original IAPS images with the means and sds taken from the manual. Group b is the altered images used in the retrieval task.\nIAPS_Fake_df \u0026lt;- read_csv(\u0026quot;data/validation_task_df.csv\u0026quot;, # import data\rcol_types = cols(Group = col_factor(levels = c(\u0026quot;b\u0026quot;, \u0026quot;a\u0026quot;)), aromn = col_number(), dommn = col_number(), valmn = col_number()), na = \u0026quot;0\u0026quot;)\r# Change to long format\rIAPS_Fake_df \u0026lt;- IAPS_Fake_df %\u0026gt;% gather(key, value, aromn, valmn, dommn) %\u0026gt;% rename(\u0026quot;Emotion\u0026quot; = key)\rIAPS_Fake_df$Emotion \u0026lt;- as.factor(IAPS_Fake_df$Emotion)\rIAPS_Fake_df$Group \u0026lt;- as.factor(IAPS_Fake_df$Group)\rlibrary(cowplot)\rIAPS_Fake_df %\u0026gt;% na.omit() %\u0026gt;% ggplot() +\raes(x = Emotion, y = value, fill = Group, colour = Group) +\rgeom_boxplot() +\rscale_fill_hue() +\rscale_color_hue() +\rlabs(x = \u0026quot;Emotion\u0026quot;, y = \u0026quot;Mean Arousal Score\u0026quot;, title = \u0026quot;Validated vs Fake Comparison\u0026quot;, subtitle = \u0026quot;Original IAPS Images with Altered Images\u0026quot;) +\rtheme_cowplot() +\rtheme(legend.position = \u0026quot;none\u0026quot;) +\rfacet_wrap(vars(Group))\rBoxplot seems to indicate we are getting pretty similar responses to the IAPS images.\nlibrary(ggpubr)\rcomparison \u0026lt;- compare_means(value ~ Emotion, group.by = \u0026quot;Group\u0026quot;, data = IAPS_Fake_df)\rcomparison\r## # A tibble: 6 x 9\r## Group .y. group1 group2 p p.adj p.format p.signif method ## \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 b value aromn dommn 0.109 0.33 0.10930 ns Wilcoxon\r## 2 b value aromn valmn 0.150 0.33 0.15010 ns Wilcoxon\r## 3 b value dommn valmn 0.00362 0.014 0.00362 ** Wilcoxon\r## 4 a value aromn dommn 0.992 0.99 0.99175 ns Wilcoxon\r## 5 a value aromn valmn 0.000505 0.0025 0.00051 *** Wilcoxon\r## 6 a value dommn valmn 0.000203 0.00120 0.00020 *** Wilcoxon\r\rData Analysis\rParticipants will show increased pattern separation scores on high arousal trials versus low-arousal trials.\n\rWe expect an interaction effect between sex and emotion, females will have a higher pattern separation score than males for negative stimuli only.\n\r\rNext post will go through how to conduct a split-plot anova and analyse the results.\n\r","date":1565913600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565915423,"objectID":"9f528f5599acc9c9945a4333a96feb78","permalink":"/post/emotional-impact-on-memory-part-2/","publishdate":"2019-08-16T00:00:00Z","relpermalink":"/post/emotional-impact-on-memory-part-2/","section":"post","summary":"This is the second part of the expriment on Pattern Separation. This processes the participants hits and misses into the induced negative or neutral group and displays some results.\nImport\rRaw CSV files with all IAPS database and images to be used in each task imported into an object.\nraw_df \u0026lt;- read_csv(\u0026quot;data/ret_task.csv\u0026quot;\r, col_types = cols(CR = col_factor(levels = c(\u0026quot;same\u0026quot;, \u0026quot;different\u0026quot;))\r, Emotion = col_factor(levels = c(\u0026quot;negative\u0026quot;, \u0026quot;neutral\u0026quot;))\r, Sex = col_factor(levels = c(\u0026quot;male\u0026quot;, \u0026quot;female\u0026quot;))))\rraw_df$CorrectAnswer \u0026lt;- recode(raw_df$CorrectAnswer, a = \u0026quot;l\u0026quot;, l = \u0026quot;a\u0026quot;)\rraw_df$Stimulus1.","tags":["Emotion","R Markdown","research"],"title":"Emotional Impact on Memory Part 2","type":"post"},{"authors":[],"categories":["R"],"content":"\rA quick walk through of running a PCA on US nutrition and the use of a couple of different packages in R, to display\rinformation graphically.\nlibrary(tidyverse)\rlibrary(corrplot)\rlibrary(cowplot)\rlibrary(hrbrthemes)\rInformation\rThe following dataset froms from the Nutrient database in the United States\nThis is from the now outdated SR27. It is also created from the full database. The abbreviated file in SR28 is more up to date than this data and contains more nutrients than we provide here. See https://data.world/awram/food-nutritional-values\nThe columns in US RDA are created using data from Dietary Reference Intakes: The Essential Guide to Nutrient Requirements available from the National Academies Press at http://www.nap.edu/catalog/11537.html\nData\rEach record is for 100 grams.\nThe columns are mostly self-explanatory. The nutrient columns end with the units, so:\nNutrient_g is in grams\rNutrient_mg is in milligrams\rNutrient_mcg is in micrograms\rNutrient_USRDA is in percentage of US Recommended Daily Allows (e.g.0.50 is 50%)\rNote that not every available RDA value in the text was used. For instance, the US RDA for Iron varies significantly by age and sex, so I deemed it easier to just leave out RDA information for Iron.\n# data_df \u0026lt;- read.csv(file = \u0026quot;https://query.data.world/s/iwzl7xgiagpimb2ixfj4fkyztngxs7\u0026quot;, stringsAsFactors = FALSE, header = TRUE)\r#write.csv(data_df, file = \u0026quot;data/nutrian_df.csv\u0026quot;) # write the dataframe to csv\rdata_df \u0026lt;- read_csv(file = \u0026quot;data/nutrian_df.csv\u0026quot;)\r\rRunning a Principle Componant Analysis on the United States Dietry Reference Nutrient Database\rThe USRDA containts the same information as _mg so these are reduntant and can be removed.\ndata_df \u0026lt;- data_df %\u0026gt;% select(-contains(\u0026quot;_USRDA\u0026quot;))\rCatagorical Visualisation\ndata_df$FoodGroup \u0026lt;- factor(data_df$FoodGroup, ordered = is.ordered(data_df$FoodGroup)) # coerce to factor\rFoodgroup_cat \u0026lt;- data_df %\u0026gt;% # Group by the food group catagory and count the amont each one occurs\rgroup_by(FoodGroup) %\u0026gt;% summarise(N = n()) %\u0026gt;% arrange(N)\rFoodgroup_cat$FoodGroup \u0026lt;- str_remove(Foodgroup_cat$FoodGroup, \u0026quot;Products\u0026quot;) # Remove the word \u0026quot;products\u0026quot; from the list\rggplot(Foodgroup_cat) +\raes(x = reorder(FoodGroup, -N), y = N) +\rgeom_bar(stat = \u0026quot;identity\u0026quot;) +\rcoord_flip() +\rlabs(title = \u0026quot;Toal Amount of Food Products\u0026quot;,\rsubtitle = \u0026quot;USDRA\u0026quot;,\rx = \u0026quot;Products\u0026quot;, y = \u0026quot;Frequency\u0026quot;) +\rtheme_ft_rc()\r\rAmount of sugar in grams associated with total energy (k/cals) for each food group\rggplot(data_df) +\raes(x = Sugar_g, y = Energy_kcal, fill = FoodGroup, colour = FoodGroup) +\rgeom_point(size = 1L) +\rscale_fill_hue() +\rscale_color_hue() +\rlabs(x = \u0026quot;Sugar in gram\u0026quot;, y = \u0026quot;Energy in k/cals\u0026quot;, title = \u0026quot;Amount of Energy from Sugar for each Food Group\u0026quot;, subtitle = \u0026quot;Food Groups\u0026quot;) +\rtheme_ft_rc() +\rtheme(legend.position = \u0026quot;none\u0026quot;) +\rfacet_wrap(vars(FoodGroup), scales = \u0026quot;free_x\u0026quot;)\rBeef, lamb, veal and game products tend to have very little sugar/energy. Theres a clustering of points in the beverages table\rand would assume this would be water or low sugar drinks. Considering this is a database of nutrients based on major food groups, we cant tease out the underlying specifics of the types of drinks or products.\nThere is some skewness in the data and could do with some transforming but theres no guarentee that it will improve results.\rHere we will rescale and center the variables with a mean of 0 and a variance of 1. Then run a correlation matrix to visualise the results.\ndata_df[,9:31] \u0026lt;- sqrt(data_df[,9:31]) # sqrt transform data_df_rescale \u0026lt;- data_df %\u0026gt;% select(9:31) %\u0026gt;% scale(center = TRUE)\rdata_df_corr \u0026lt;- data_df %\u0026gt;% select(9:31)\rdata_corrr \u0026lt;- cor(data_df_corr)\rcorrplot(as.matrix(data_corrr), is.corr = FALSE, method = \u0026quot;square\u0026quot;, type = \u0026quot;full\u0026quot;)\rRun a PCA with the default prcomp function in R and run a summary on the object then display a scree plot with eigen vectors:\ndata_PCA \u0026lt;- prcomp(data_df_rescale)\r# print(data_PCA) # Full PCA matrix\rsummary(data_PCA) \r## Importance of components:\r## PC1 PC2 PC3 PC4 PC5 PC6\r## Standard deviation 2.7035 1.9212 1.42556 1.24459 1.17551 0.96650\r## Proportion of Variance 0.3178 0.1605 0.08836 0.06735 0.06008 0.04061\r## Cumulative Proportion 0.3178 0.4783 0.56661 0.63396 0.69404 0.73465\r## PC7 PC8 PC9 PC10 PC11 PC12\r## Standard deviation 0.92451 0.81294 0.77169 0.73023 0.71235 0.68914\r## Proportion of Variance 0.03716 0.02873 0.02589 0.02318 0.02206 0.02065\r## Cumulative Proportion 0.77182 0.80055 0.82644 0.84963 0.87169 0.89234\r## PC13 PC14 PC15 PC16 PC17 PC18\r## Standard deviation 0.61955 0.60078 0.55051 0.51154 0.48452 0.46802\r## Proportion of Variance 0.01669 0.01569 0.01318 0.01138 0.01021 0.00952\r## Cumulative Proportion 0.90903 0.92472 0.93789 0.94927 0.95948 0.96900\r## PC19 PC20 PC21 PC22 PC23\r## Standard deviation 0.45204 0.4317 0.38515 0.37130 0.18989\r## Proportion of Variance 0.00888 0.0081 0.00645 0.00599 0.00157\r## Cumulative Proportion 0.97789 0.9860 0.99244 0.99843 1.00000\rplot(data_PCA, type = \u0026quot;l\u0026quot;)\r# data_PCA$rotation\rThe summary method describe the importance of the PCs. The first row describe again the standard deviation associated with each PC. The second row shows the proportion of the variance in the data explained by each component while the third row describe the cumulative proportion of explained variance. We can see there that the first two PCs accounts for more than 47% (0.31+0.16) of the variance of the data. The remaining 53% is shared across PC3 to PC23.\nFrom the plot we can see that factors load the most on PC1 and PC2. The Scree plot also shows us visualy where the components fall off after PC1 and PC2. Use the FactorMineR package to extract more detailed data howver, will use the first 5 components as these tend to load the most on the components (69%).\nlibrary(FactoMineR)\rdata_PCA_all \u0026lt;- PCA(data_df_rescale, ncp = 2, graph = TRUE)\rdata_PCA_all$eig #eigen values, percent of varaince and cumulative percentage\r## eigenvalue percentage of variance\r## comp 1 7.30899804 31.7782524\r## comp 2 3.69088747 16.0473368\r## comp 3 2.03221880 8.8357339\r## comp 4 1.54900652 6.7348110\r## comp 5 1.38181755 6.0079024\r## comp 6 0.93411330 4.0613622\r## comp 7 0.85472741 3.7162061\r## comp 8 0.66087037 2.8733494\r## comp 9 0.59551138 2.5891799\r## comp 10 0.53323222 2.3184010\r## comp 11 0.50743683 2.2062471\r## comp 12 0.47491477 2.0648468\r## comp 13 0.38384585 1.6688950\r## comp 14 0.36094051 1.5693065\r## comp 15 0.30306178 1.3176599\r## comp 16 0.26167535 1.1377189\r## comp 17 0.23475988 1.0206951\r## comp 18 0.21904338 0.9523625\r## comp 19 0.20433782 0.8884253\r## comp 20 0.18634147 0.8101803\r## comp 21 0.14834034 0.6449580\r## comp 22 0.13786150 0.5993978\r## comp 23 0.03605747 0.1567716\r## cumulative percentage of variance\r## comp 1 31.77825\r## comp 2 47.82559\r## comp 3 56.66132\r## comp 4 63.39613\r## comp 5 69.40404\r## comp 6 73.46540\r## comp 7 77.18160\r## comp 8 80.05495\r## comp 9 82.64413\r## comp 10 84.96254\r## comp 11 87.16878\r## comp 12 89.23363\r## comp 13 90.90252\r## comp 14 92.47183\r## comp 15 93.78949\r## comp 16 94.92721\r## comp 17 95.94790\r## comp 18 96.90027\r## comp 19 97.78869\r## comp 20 98.59887\r## comp 21 99.24383\r## comp 22 99.84323\r## comp 23 100.00000\rdata_PCA_all$var$coord # correlations betwewen variables and PCs\r## Dim.1 Dim.2\r## Energy_kcal 0.448057415 0.15136222\r## Protein_g 0.652364089 -0.58221037\r## Fat_g 0.249819599 -0.18205001\r## Carb_g 0.158105970 0.85394168\r## Sugar_g -0.004775929 0.65028120\r## Fiber_g 0.251606686 0.74499520\r## VitA_mcg 0.307971932 0.13860307\r## VitB6_mg 0.772433885 -0.09606918\r## VitB12_mcg 0.547003966 -0.50985668\r## VitC_mg 0.043794729 0.40875652\r## VitE_mg 0.267686499 0.19364742\r## Folate_mcg 0.591668201 0.39794955\r## Niacin_mg 0.807997717 -0.19436594\r## Riboflavin_mg 0.812785526 0.02361212\r## Thiamin_mg 0.716976586 0.23537745\r## Calcium_mg 0.413959708 0.36642193\r## Copper_mcg 0.601837302 0.10344439\r## Iron_mg 0.743808829 0.24374640\r## Magnesium_mg 0.716083740 0.27292863\r## Manganese_mg 0.376447365 0.37623498\r## Phosphorus_mg 0.780578918 -0.20048927\r## Selenium_mcg 0.584192531 -0.52000769\r## Zinc_mg 0.773393089 -0.33565448\rWhen variables correlate strongly together they all converge on the same component. A simple method to extract the results, for variables, from a PCA output is to use the function get_pca_var() [factoextra package]. This function provides a list of matrices containing all the results for the active variables (coordinates, correlation between variables and axes, squared cosine and contributions)\nThis provides a nicer toolset to work with and display the PCA data:\nlibrary(factoextra)\r# a more colourful visual representation of the variables and where they converge on a component. fviz_pca_var(data_PCA_all\r, col.var = \u0026quot;cos2\u0026quot;\r, gradient.cols = c(\u0026quot;#00AFBB\u0026quot;, \u0026quot;#E7B800\u0026quot;, \u0026quot;#FC4E07\u0026quot;)\r, repel = TRUE) # Avoid text overlapping)\rget_eig(data_PCA_all) # display the eigen values, dimensions and variance\r## eigenvalue variance.percent cumulative.variance.percent\r## Dim.1 7.30899804 31.7782524 31.77825\r## Dim.2 3.69088747 16.0473368 47.82559\r## Dim.3 2.03221880 8.8357339 56.66132\r## Dim.4 1.54900652 6.7348110 63.39613\r## Dim.5 1.38181755 6.0079024 69.40404\r## Dim.6 0.93411330 4.0613622 73.46540\r## Dim.7 0.85472741 3.7162061 77.18160\r## Dim.8 0.66087037 2.8733494 80.05495\r## Dim.9 0.59551138 2.5891799 82.64413\r## Dim.10 0.53323222 2.3184010 84.96254\r## Dim.11 0.50743683 2.2062471 87.16878\r## Dim.12 0.47491477 2.0648468 89.23363\r## Dim.13 0.38384585 1.6688950 90.90252\r## Dim.14 0.36094051 1.5693065 92.47183\r## Dim.15 0.30306178 1.3176599 93.78949\r## Dim.16 0.26167535 1.1377189 94.92721\r## Dim.17 0.23475988 1.0206951 95.94790\r## Dim.18 0.21904338 0.9523625 96.90027\r## Dim.19 0.20433782 0.8884253 97.78869\r## Dim.20 0.18634147 0.8101803 98.59887\r## Dim.21 0.14834034 0.6449580 99.24383\r## Dim.22 0.13786150 0.5993978 99.84323\r## Dim.23 0.03605747 0.1567716 100.00000\rfviz_eig(data_PCA_all) # screeplot\rcorrplot(data_PCA_all$var$cor, is.corr=FALSE) \rfviz_contrib(data_PCA_all, choice = \u0026quot;var\u0026quot;, axes = 1:2, top = 10)\rFinally, with the Ggforce package we are able to plot multiple components from a PCA analysis against each other component:\nlibrary(ggforce)\rpca_grid \u0026lt;- as.data.frame(data_PCA$rotation)\r# Since the first ttwo compomnents make up most of the variance explain will add the\r# 5 to make up 77% of the components for this example\rggplot(pca_grid[,1:7], aes(x = .panel_x, y = .panel_y)) + geom_point(alpha = 0.9, shape = 16, size = 0.5) + geom_autodensity() +\rgeom_density2d() +\rfacet_matrix(vars(everything()), layer.diag = 2, layer.upper = 3, grid.y.diag = FALSE)\r\r","date":1565308800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565312418,"objectID":"814a44d2186e5380f296794c07e06d73","permalink":"/post/pca-on-us-nutrition/","publishdate":"2019-08-09T00:00:00Z","relpermalink":"/post/pca-on-us-nutrition/","section":"post","summary":"A quick walk through of running a PCA on US nutrition and the use of a couple of different packages in R, to display\rinformation graphically.\nlibrary(tidyverse)\rlibrary(corrplot)\rlibrary(cowplot)\rlibrary(hrbrthemes)\rInformation\rThe following dataset froms from the Nutrient database in the United States\nThis is from the now outdated SR27. It is also created from the full database. The abbreviated file in SR28 is more up to date than this data and contains more nutrients than we provide here.","tags":["PCA","R Markdown"],"title":"PCA on US Nutrition","type":"post"},{"authors":[],"categories":["R"],"content":"\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\rProcessing an image database for use in a experiment to induce an emotional state in particpants.\nResearch Protocol\rlibrary(tidyverse)\rlibrary(stringr)\rlibrary(knitr)\rlibrary(plotly)\rlibrary(gridExtra)\rlibrary(inspectdf)\rlibrary(DT)\rThe following was the code used to prepare images from the IAPS database for a experiment on pattern separation. The participants were seated in front of a PC and went through three tasks: Encoding, retreival and validation. We were provided with a folder of approved images and a text file with unapproved images.\n\rRaw text to selected IAPS images\rA raw text file was provided with the IAPS database image details I then used a script to then compare the images in the memory task folder and made a raw dataframe with all the IAPS data. There are 200 images overall. Old, new and fake conditions were added based on coding from the images folder.\niaps_dataframe_images \u0026lt;- read_csv(\u0026quot;data/iaps_raw.csv\u0026quot;) #List of all IAPS images\rRP_images \u0026lt;- read_csv(\u0026quot;data/new_old_images.csv\u0026quot;) #list of images used in our research protocol\rRP_images \u0026lt;- as.matrix(RP_images) # convert to matrix\rENC_orig_RET_New \u0026lt;- na.omit(str_match(RP_images, \u0026quot;^[[:digit:]]+\\\\.*[[:digit:]]*$\u0026quot;)) # _ENC_ORIGINAL_50 whats left over RET_UNSEEN_NEW\rRET_PS_a \u0026lt;- na.omit(str_match(RP_images, \u0026quot;[[:digit:]]{4}a$\u0026quot;)) # _RET_PS_a 50\rENC_ORIGINAL_b \u0026lt;- na.omit(str_match(RP_images, \u0026quot;[[:digit:]]{4}b$\u0026quot;)) # _ENC_ORIGINAL_b 50\r# RET_UNSEEN_NEW\rall_images_list \u0026lt;- cbind(c(ENC_orig_RET_New, RET_PS_a, ENC_ORIGINAL_b))\r# match IAPS numbers to ones we have selected for RP\rgroup39_df \u0026lt;- filter(iaps_dataframe_images, nr %in% str_extract(all_images_list, \u0026quot;\\\\d{4}\u0026quot;))\r\rNegative and Neutral Images\rThe following functions compare the iaps_dataframe_images using the nr column numbers to the\rvectors made previously above.\nHighly negative and neutral images were coded by looking at the means and then\rcoding highly aroused negative images that have a mean greater than 4.5. All neutral low\rneutral images were coded with valence means less than 4.0.\nA dataframe of all the images being used in the experiment are then stored into the group39_df.\rENC_RET_ORIG_UNSEEN needs to be seperated with 50 images to be used in the retrieval task.\ngroup39_df_mutate \u0026lt;- group39_df %\u0026gt;% #Create Negative and Neutral cases\rselect_all() %\u0026gt;% mutate(\rEmotion = case_when(\raromn \u0026gt; 4.5 ~ \u0026quot;Negative\u0026quot;, valmn \u0026gt; 4.0 ~ \u0026quot;Neutral\u0026quot;))\rgroup39_df \u0026lt;- group39_df_mutate\r# Core master list of all images core_images_df \u0026lt;- filter(group39_df, Condition != \u0026quot;RET_PS_a\u0026quot;)\r# \rWe have three tasks: Encoding, Retreival and Validation. The images that were marked a or b are the ones\rthat have been photoshopped to look like their counterparts. However, we need to take the 100 images that are\rnot marked and split them so that half are used in the encoding and the ones not used, introduced into the\rretrieval task and marked as new/unseen.\nThe group39_df also has all the negative and neutral emotion conditions attached to eaech image so we can now filter accordingly.\nencoding_list \u0026lt;- filter(group39_df, Condition == \u0026quot;ENC_RET_ORIG_UNSEEN\u0026quot;) %\u0026gt;% arrange(Emotion) # filter the raw list by first 100\rnrowgen\u0026lt;-function(x,y) #Function to sort a list by every second row\r{\rn\u0026lt;-nrow(x)\rb\u0026lt;-seq(1,n,y)\rr\u0026lt;-length(b)\rc=data.frame()\r{\rfor(i in 1:r)\r{\rabc\u0026lt;-x[b[i],]\rc\u0026lt;-rbind(c,abc)\r}\rreturn(c)\r}\r}\r# RET TASK 50 images\rRET_UNSEEN_NEW \u0026lt;- nrowgen(encoding_list, 2) # select every second row - original DF arranged by emotion\r# ENC TASK 50 images\rENC_ONLY_ORIG \u0026lt;- anti_join(encoding_list, RET_UNSEEN_NEW)\r# match those columns that arent in the unseen list\r# 50 Fake photoshopped images for the ret task RET_FAKE_a \u0026lt;- filter(group39_df, Condition == \u0026quot;RET_PS_a\u0026quot;)\rENC_ORIG_b \u0026lt;- filter(group39_df, Condition == \u0026quot;ENC_ORIGINAL_b\u0026quot;)\r# Validation task\rVAL_TASK \u0026lt;- filter(group39_df, Condition == \u0026quot;RET_PS_a\u0026quot;) %\u0026gt;% arrange(nr)\rRET_SEEN \u0026lt;- ENC_ONLY_ORIG\r# Change the condition name\rRET_SEEN$Condition[RET_SEEN$Condition == \u0026quot;ENC_RET_ORIG_UNSEEN\u0026quot;] \u0026lt;- \u0026quot;RET_SEEN\u0026quot;\rRET_FAKE_a$Condition[RET_FAKE_a$Condition == \u0026quot;RET_PS_a\u0026quot;] \u0026lt;- \u0026quot;RET_FAKE_a\u0026quot;\rRET_UNSEEN_NEW$Condition[RET_UNSEEN_NEW$Condition == \u0026quot;ENC_RET_ORIG_UNSEEN\u0026quot;] \u0026lt;- \u0026quot;RET_UNSEEN_NEW\u0026quot;\rENC_ONLY_ORIG$Condition[ENC_ONLY_ORIG$Condition == \u0026quot;ENC_RET_ORIG_UNSEEN\u0026quot;] \u0026lt;- \u0026quot;ENC_ONLY\u0026quot;\rWe now have vectors with all the information needed. Below are the dataframes for eaech task and then joined together\rto create the main spreadsheet for use in the lab.\n# Full join of tables\rabc \u0026lt;- full_join(ENC_ONLY_ORIG, ENC_ORIG_b)\rdef \u0026lt;- full_join(RET_UNSEEN_NEW, RET_FAKE_a)\rxyz \u0026lt;- full_join(abc, def)\rTask_Spreadsheet \u0026lt;- full_join(xyz, RET_SEEN)\rdatatable(Task_Spreadsheet, class = \u0026#39;cell-border stripe\u0026#39;\r, caption = \u0026#39;All IAPS database images used for the experiment\u0026#39;)\r\r{\"x\":{\"filter\":\"none\",\"caption\":\"All IAPS database images used for the experiment\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\",\"151\",\"152\",\"153\",\"154\",\"155\",\"156\",\"157\",\"158\",\"159\",\"160\",\"161\",\"162\",\"163\",\"164\",\"165\",\"166\",\"167\",\"168\",\"169\",\"170\",\"171\",\"172\",\"173\",\"174\",\"175\",\"176\",\"177\",\"178\",\"179\",\"180\",\"181\",\"182\",\"183\",\"184\",\"185\",\"186\",\"187\",\"188\",\"189\",\"190\",\"191\",\"192\",\"193\",\"194\",\"195\",\"196\",\"197\",\"198\",\"199\",\"200\",\"201\",\"202\",\"203\",\"204\",\"205\",\"206\",\"207\",\"208\",\"209\",\"210\",\"211\",\"212\",\"213\",\"214\",\"215\",\"216\",\"217\",\"218\",\"219\",\"220\",\"221\",\"222\",\"223\",\"224\",\"225\",\"226\",\"227\",\"228\",\"229\",\"230\",\"231\",\"232\",\"233\",\"234\",\"235\",\"236\",\"237\",\"238\",\"239\",\"240\",\"241\",\"242\",\"243\",\"244\",\"245\",\"246\",\"247\",\"248\",\"249\",\"250\"],[\"War\",\"DeerHead\",\"Gold\",\"Accident\",\"Mutilation\",\"Mutilation\",\"Injury\",\"Mutilation\",\"Mutilation\",\"Surgery\",\"Tumor\",\"Attack\",\"Attack\",\"Attack\",\"Gang\",\"Police\",\"Boxer\",\"HurtDog\",\"WarVictim\",\"Vomit\",\"Hanging\",\"DeadMan\",\"Skinhead\",\"CarAccident\",\"Fire\",\"Gannet\",\"NeuWoman\",\"Girl\",\"Chess\",\"Satellite\",\"Farmland\",\"Nature\",\"Buttons\",\"GasCan\",\"Scissors\",\"Video\",\"Iron\",\"Mug\",\"Baskets\",\"HairDryer\",\"Lightbulb\",\"TrashCan\",\"Bus\",\"Fabric\",\"Rug\",\"AbstractArt\",\"ClothesRack\",\"Building\",\"Office\",\"EmptyPool\",\"AttackDog\",\"Woman\",\"Tourist\",\"Shadow\",\"HeadlessBody\",\"Mutilation\",\"Organs\",\"BurnVictim\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"BurnVictim\",\"BurnVictim\",\"Mutilation\",\"BabyTumor\",\"SeveredHand\",\"Boat\",\"Mushroom\",\"Plant\",\"Clouds\",\"Assault\",\"AimedGun\",\"BeatenFem\",\"Attack\",\"Suicide\",\"RollingPin\",\"Towel\",\"Spoon\",\"Bowl\",\"Mug\",\"Basket\",\"PicnicTable\",\"Hammer\",\"Shoes\",\"DustPan\",\"Barbells\",\"Fork\",\"Book\",\"Lamp\",\"Man\",\"Office\",\"Cabinet\",\"Tissue\",\"Fire\",\"Soldiers\",\"Dirty\",\"Soldier\",\"Execution\",\"Dog\",\"Kiss\",\"NativeBoy\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"DeadBody\",\"Mutilation\",\"Stitches\",\"Surgery\",\"Attack\",\"Soldier\",\"DeadTiger\",\"Attack\",\"Guns\",\"Police\",\"PlaneCrash\",\"InjuredDog\",\"DeadBody\",\"DeadMan\",\"Assault\",\"Porpoises\",\"KKKrally\",\"CarAccident\",\"Parrots\",\"Grouper\",\"Fingerprint\",\"Factoryworker\",\"Rocks\",\"Field\",\"Field\",\"Leaves\",\"Disk\",\"Rubberbands\",\"Razor\",\"Fan\",\"Shoes\",\"Train\",\"Zipper\",\"Clothespins\",\"Tool\",\"FireHydrant\",\"Umbrella\",\"Pole\",\"AbstractArt\",\"Scarves\",\"Building\",\"Bridge\",\"Rain\",\"AttackDog\",\"Woman\",\"Tourist\",\"Shadow\",\"HeadlessBody\",\"Mutilation\",\"Organs\",\"BurnVictim\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"BurnVictim\",\"BurnVictim\",\"Mutilation\",\"BabyTumor\",\"SeveredHand\",\"Boat\",\"Mushroom\",\"Plant\",\"Clouds\",\"Assault\",\"AimedGun\",\"BeatenFem\",\"Attack\",\"Suicide\",\"RollingPin\",\"Towel\",\"Spoon\",\"Bowl\",\"Mug\",\"Basket\",\"PicnicTable\",\"Hammer\",\"Shoes\",\"DustPan\",\"Barbells\",\"Fork\",\"Book\",\"Lamp\",\"Man\",\"Office\",\"Cabinet\",\"Tissue\",\"Fire\",\"Soldiers\",\"Dirty\",\"Soldier\",\"Execution\",\"Dog\",\"War\",\"DeerHead\",\"Gold\",\"Accident\",\"Mutilation\",\"Mutilation\",\"Injury\",\"Mutilation\",\"Mutilation\",\"Surgery\",\"Tumor\",\"Attack\",\"Attack\",\"Attack\",\"Gang\",\"Police\",\"Boxer\",\"HurtDog\",\"WarVictim\",\"Vomit\",\"Hanging\",\"DeadMan\",\"Skinhead\",\"CarAccident\",\"Fire\",\"Gannet\",\"NeuWoman\",\"Girl\",\"Chess\",\"Satellite\",\"Farmland\",\"Nature\",\"Buttons\",\"GasCan\",\"Scissors\",\"Video\",\"Iron\",\"Mug\",\"Baskets\",\"HairDryer\",\"Lightbulb\",\"TrashCan\",\"Bus\",\"Fabric\",\"Rug\",\"AbstractArt\",\"ClothesRack\",\"Building\",\"Office\",\"EmptyPool\"],[2683,2981,3005,3015,3064,3069,3103,3130,3168,3212,3261,3530,6370,6510,6821,6834,8230,9183,9250,9321,9413,9433,9800,9904,9921,1450,2038,2320,2580,5471,5720,5750,7001,7011,7014,7017,7030,7035,7041,7050,7055,7060,7140,7160,7179,7188,7217,7500,7700,9360,1525,2036,2850,2880,3001,3016,3019,3053,3059,3062,3063,3071,3100,3110,3150,3170,3400,5390,5500,5740,5870,6021,6230,6315,6550,6570,7000,7002,7004,7006,7009,7010,7026,7034,7038,7040,7042,7080,7090,7175,7493,7550,7705,7950,8485,9163,9300,9410,9414,9570,2352,2730,3000,3010,3030,3068,3080,3120,3131,3195,3213,3500,6212,6415,6520,6830,6838,9050,9187,9252,9412,9425,9500,9810,9908,1333,1910,2206,2393,5130,5711,5725,5800,7003,7012,7016,7020,7031,7039,7045,7052,7056,7100,7150,7161,7187,7205,7491,7547,9210,1525,2036,2850,2880,3001,3016,3019,3053,3059,3062,3063,3071,3100,3110,3150,3170,3400,5390,5500,5740,5870,6021,6230,6315,6550,6570,7000,7002,7004,7006,7009,7010,7026,7034,7038,7040,7042,7080,7090,7175,7493,7550,7705,7950,8485,9163,9300,9410,9414,9570,2683,2981,3005,3015,3064,3069,3103,3130,3168,3212,3261,3530,6370,6510,6821,6834,8230,9183,9250,9321,9413,9433,9800,9904,9921,1450,2038,2320,2580,5471,5720,5750,7001,7011,7014,7017,7030,7035,7041,7050,7055,7060,7140,7160,7179,7188,7217,7500,7700,9360],[2.62,2.76,5.98,1.52,1.45,1.7,2.07,1.58,1.56,2.79,1.82,1.8,2.7,2.46,2.38,2.91,2.95,1.69,2.57,2.81,1.76,1.84,2.04,2.39,2.04,6.37,5.09,6.17,5.71,5.21,6.31,6.6,5.32,4.52,5.15,5.18,4.69,4.98,4.99,4.93,4.9,4.43,5.5,5.02,5.06,5.5,4.82,5.33,4.25,4.03,3.09,5.8,5.22,5.18,1.62,1.9,2.99,1.31,1.81,1.87,1.49,1.88,1.6,1.79,2.26,1.46,2.35,5.59,5.42,5.21,6.78,2.21,2.37,2.31,2.73,2.19,5,4.97,5.04,4.88,4.93,4.94,5.38,4.95,4.82,4.69,5.55,5.27,5.19,4.87,5.35,5.27,4.77,4.94,2.73,2.1,2.26,1.51,2.06,1.68,6.94,2.45,1.45,1.71,1.91,1.8,1.48,1.56,1.51,2.06,2.96,2.21,2.19,2.21,1.94,2.82,2.45,2.43,1.81,1.98,1.83,2.67,2.42,2.09,2.34,6.11,6.71,4.06,4.87,4.45,6.62,7.09,6.36,5,4.98,4.76,4.97,4.52,5.93,4.97,5.33,5.07,5.24,4.72,4.98,5.07,5.56,4.82,5.21,4.53,3.09,5.8,5.22,5.18,1.62,1.9,2.99,1.31,1.81,1.87,1.49,1.88,1.6,1.79,2.26,1.46,2.35,5.59,5.42,5.21,6.78,2.21,2.37,2.31,2.73,2.19,5,4.97,5.04,4.88,4.93,4.94,5.38,4.95,4.82,4.69,5.55,5.27,5.19,4.87,5.35,5.27,4.77,4.94,2.73,2.1,2.26,1.51,2.06,1.68,2.62,2.76,5.98,1.52,1.45,1.7,2.07,1.58,1.56,2.79,1.82,1.8,2.7,2.46,2.38,2.91,2.95,1.69,2.57,2.81,1.76,1.84,2.04,2.39,2.04,6.37,5.09,6.17,5.71,5.21,6.31,6.6,5.32,4.52,5.15,5.18,4.69,4.98,4.99,4.93,4.9,4.43,5.5,5.02,5.06,5.5,4.82,5.33,4.25,4.03],[1.78,1.94,1.9,0.95,0.97,1.41,1.27,1.24,1.06,1.67,1.34,1.32,1.52,1.58,1.72,1.73,1.88,1.1,1.39,2.14,1.08,1.19,1.57,1.36,1.47,1.62,1.35,1.51,1.41,1.18,1.6,1.84,1.19,1.16,0.97,1.07,1.04,0.96,1.12,0.81,0.64,1.16,1.42,1.1,1.05,1.12,0.99,1.44,1.45,1.38,1.72,1.28,1.39,1.44,1.14,1.31,1.74,0.97,1.24,1.31,0.96,1.39,1.07,1.3,1.57,1.01,1.9,1.54,1.58,1.38,1.76,1.51,1.57,1.69,2.38,1.72,0.84,0.97,0.6,0.99,1,1.07,1.26,0.87,1.2,1.09,1.23,1.09,1.46,1,1.34,1.4,1.02,1.21,1.62,1.36,1.76,1.15,1.48,1.23,1.87,2.25,1.2,1.19,1.56,1.56,0.95,1.09,0.97,1.23,1.94,1.34,1.49,1.51,1.27,1.81,1.44,1.61,1.36,1.59,1.37,1.44,1.73,1.78,1.49,1.5,1.8,1.4,1.06,1.13,1.65,1.41,1.7,1.22,1.05,1.08,1.04,1.11,1.58,0.76,1.32,1.02,1.2,1,1.02,1.02,1.39,1.03,0.96,1.82,1.72,1.28,1.39,1.44,1.14,1.31,1.74,0.97,1.24,1.31,0.96,1.39,1.07,1.3,1.57,1.01,1.9,1.54,1.58,1.38,1.76,1.51,1.57,1.69,2.38,1.72,0.84,0.97,0.6,0.99,1,1.07,1.26,0.87,1.2,1.09,1.23,1.09,1.46,1,1.34,1.4,1.02,1.21,1.62,1.36,1.76,1.15,1.48,1.23,1.78,1.94,1.9,0.95,0.97,1.41,1.27,1.24,1.06,1.67,1.34,1.32,1.52,1.58,1.72,1.73,1.88,1.1,1.39,2.14,1.08,1.19,1.57,1.36,1.47,1.62,1.35,1.51,1.41,1.18,1.6,1.84,1.19,1.16,0.97,1.07,1.04,0.96,1.12,0.81,0.64,1.16,1.42,1.1,1.05,1.12,0.99,1.44,1.45,1.38],[6.21,5.97,4.84,5.9,6.41,7.03,6.06,6.97,6,6.57,5.75,6.82,6.44,6.96,6.29,6.28,5.91,6.58,6.6,6.24,6.81,5.89,6.05,6.08,6.52,2.83,2.94,2.9,2.79,3.26,2.79,3.14,3.2,3.81,3.25,3.12,2.99,2.66,2.6,2.75,3.02,2.55,2.92,3.07,2.88,4.28,2.43,3.26,2.95,2.63,6.51,3.24,3,2.96,6.64,5.82,6.3,6.91,6.48,5.78,6.35,6.86,6.49,6.7,6.55,7.21,6.91,2.88,3,2.59,3.1,6.06,7.35,6.38,7.09,6.24,2.42,3.16,2,2.33,3.01,1.76,2.63,3.06,3.01,2.69,4.02,2.32,2.61,1.72,3.39,3.95,2.65,2.28,6.46,6.53,6,7.07,6.49,6.14,4.99,6.8,7.26,7.16,6.76,6.77,7.22,6.84,6.61,6.36,6.82,6.99,6.01,6.2,6.59,6.21,5.8,6.36,6.45,6.64,6.72,5.92,5.82,6.62,6.63,3.17,3.29,3.71,2.93,2.51,3.03,3.55,2.51,3.07,3,3.4,2.17,2.03,3.29,3.32,3.01,3.07,2.89,2.61,2.98,2.3,2.93,2.39,3.18,3.08,6.51,3.24,3,2.96,6.64,5.82,6.3,6.91,6.48,5.78,6.35,6.86,6.49,6.7,6.55,7.21,6.91,2.88,3,2.59,3.1,6.06,7.35,6.38,7.09,6.24,2.42,3.16,2,2.33,3.01,1.76,2.63,3.06,3.01,2.69,4.02,2.32,2.61,1.72,3.39,3.95,2.65,2.28,6.46,6.53,6,7.07,6.49,6.14,6.21,5.97,4.84,5.9,6.41,7.03,6.06,6.97,6,6.57,5.75,6.82,6.44,6.96,6.29,6.28,5.91,6.58,6.6,6.24,6.81,5.89,6.05,6.08,6.52,2.83,2.94,2.9,2.79,3.26,2.79,3.14,3.2,3.81,3.25,3.12,2.99,2.66,2.6,2.75,3.02,2.55,2.92,3.07,2.88,4.28,2.43,3.26,2.95,2.63],[2.15,2.12,2.18,2.82,2.62,2.41,2.3,2.07,2.46,1.99,2.64,2.09,2.19,2.09,2.02,1.9,2.15,2.12,1.87,2.23,2.09,2.6,2.71,2.06,1.94,1.87,1.93,1.89,1.78,2.05,2.2,2.25,2.15,1.67,2.03,1.97,2.09,1.82,1.78,1.8,1.83,1.77,2.38,2.07,1.97,2.16,1.64,2.18,2.17,1.75,2.25,1.88,1.94,1.94,2.54,2.44,2.14,2.57,2.32,2.57,2.6,2.05,2.23,2.16,2.2,1.99,2.22,1.97,2.42,1.99,2.22,2.38,2.01,2.39,1.98,2.16,1.79,2,1.66,1.67,1.97,1.48,1.93,1.95,1.96,1.93,2.26,1.84,2.03,1.26,2.08,1.91,1.88,1.81,2.1,2.21,2.41,2.06,2.26,2.31,1.98,2.21,2.1,2.24,2.1,2.49,1.97,2.36,2.34,2.25,2,2.19,2.44,2.31,2.08,2.23,2.09,1.97,2.3,2.33,2.07,2.13,2.29,2.26,2.13,1.97,2.29,2.03,1.88,1.72,1.96,2.32,2.01,1.98,1.94,1.71,1.71,1.51,2.15,1.96,2.02,1.92,1.7,1.76,1.99,1.75,2.16,1.9,2.01,2.13,2.25,1.88,1.94,1.94,2.54,2.44,2.14,2.57,2.32,2.57,2.6,2.05,2.23,2.16,2.2,1.99,2.22,1.97,2.42,1.99,2.22,2.38,2.01,2.39,1.98,2.16,1.79,2,1.66,1.67,1.97,1.48,1.93,1.95,1.96,1.93,2.26,1.84,2.03,1.26,2.08,1.91,1.88,1.81,2.1,2.21,2.41,2.06,2.26,2.31,2.15,2.12,2.18,2.82,2.62,2.41,2.3,2.07,2.46,1.99,2.64,2.09,2.19,2.09,2.02,1.9,2.15,2.12,1.87,2.23,2.09,2.6,2.71,2.06,1.94,1.87,1.93,1.89,1.78,2.05,2.2,2.25,2.15,1.67,2.03,1.97,2.09,1.82,1.78,1.8,1.83,1.77,2.38,2.07,1.97,2.16,1.64,2.18,2.17,1.75],[null,null,null,2.84,2.63,null,3.37,3.46,3.24,4.07,3.57,2.81,3,2.81,3.29,3.9,4.05,2.96,3.73,3.9,2.75,3.37,4.92,3.4,3.57,6.75,null,6.66,5.88,null,5.58,6.82,5.82,4.99,6.21,5.93,5.73,6.39,null,5.82,null,5.85,5.45,5.8,null,null,6.25,5.17,5.13,5.34,null,6.1,5.87,6.01,2.66,null,4.25,2.33,2.88,3.73,2.7,3.28,3,3.04,3.39,2.7,3.65,6.33,6.45,6.27,5.2,null,2.15,null,3.01,4.03,6.14,6.25,6.74,6.18,6.33,6.7,6.19,6.48,null,5.46,null,7.04,6.65,6.47,null,5.22,6.39,6.3,null,3.04,4.12,2.81,3.11,3.37,6.32,3.94,2.99,2.88,3.69,null,2.85,3.32,2.73,3.55,3.92,2.4,3.45,null,2.88,3.67,3.79,3.27,3.17,2.92,3,null,3.42,3.95,2.79,null,6.44,4.46,null,5.84,null,6.23,5.72,6.02,6.06,5.74,6.16,6.14,null,6.28,null,null,5.92,5.55,null,6.1,6.39,5.93,null,4.55,null,6.1,5.87,6.01,2.66,null,4.25,2.33,2.88,3.73,2.7,3.28,3,3.04,3.39,2.7,3.65,6.33,6.45,6.27,5.2,null,2.15,null,3.01,4.03,6.14,6.25,6.74,6.18,6.33,6.7,6.19,6.48,null,5.46,null,7.04,6.65,6.47,null,5.22,6.39,6.3,null,3.04,4.12,2.81,3.11,3.37,null,null,null,2.84,2.63,null,3.37,3.46,3.24,4.07,3.57,2.81,3,2.81,3.29,3.9,4.05,2.96,3.73,3.9,2.75,3.37,4.92,3.4,3.57,6.75,null,6.66,5.88,null,5.58,6.82,5.82,4.99,6.21,5.93,5.73,6.39,null,5.82,null,5.85,5.45,5.8,null,null,6.25,5.17,5.13,5.34],[null,null,null,2.13,2.04,null,2,2.07,2.31,2.25,2.38,1.97,1.87,2.12,2.36,2.28,2.36,1.85,1.94,2.35,2.21,2.16,2.52,2.21,2.41,1.87,null,1.81,1.89,null,2.15,2.25,2.02,1.78,1.86,1.94,2,1.94,null,1.93,null,2.1,1.78,1.97,null,null,1.86,2.05,2.45,2.08,null,1.79,1.97,2.05,2,null,2.29,1.94,2.1,2.5,2.02,2.15,2.16,1.97,2.15,1.89,2.21,2.02,2.42,2.21,2.13,null,2.09,null,2.41,2.52,2.14,1.93,1.99,1.96,1.93,1.48,1.76,1.86,null,1.64,null,1.84,2.03,2.04,null,2.26,2.09,2.11,null,2.24,2.57,1.99,2.23,2.23,1.68,2.55,2.1,2.41,2.1,null,2.1,2.36,1.93,2.15,2.44,1.88,2.1,null,2.16,2.5,2.08,2.06,2.11,2.28,2.32,null,2.31,2.5,2.12,null,2.13,2.36,null,1.98,null,2.31,2.03,1.87,1.77,1.98,2.15,2.12,null,1.72,null,null,1.73,2.01,null,2.04,1.95,1.96,null,1.9,null,1.79,1.97,2.05,2,null,2.29,1.94,2.1,2.5,2.02,2.15,2.16,1.97,2.15,1.89,2.21,2.02,2.42,2.21,2.13,null,2.09,null,2.41,2.52,2.14,1.93,1.99,1.96,1.93,1.48,1.76,1.86,null,1.64,null,1.84,2.03,2.04,null,2.26,2.09,2.11,null,2.24,2.57,1.99,2.23,2.23,null,null,null,2.13,2.04,null,2,2.07,2.31,2.25,2.38,1.97,1.87,2.12,2.36,2.28,2.36,1.85,1.94,2.35,2.21,2.16,2.52,2.21,2.41,1.87,null,1.81,1.89,null,2.15,2.25,2.02,1.78,1.86,1.94,2,1.94,null,1.93,null,2.1,1.78,1.97,null,null,1.86,2.05,2.45,2.08],[3.43,4.16,5.97,null,null,2.62,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,2.94,null,6.36,null,null,5.63,null,null,null,null,null,null,null,null,6.35,null,5.73,null,null,null,6.1,5.61,null,null,null,null,3.15,null,null,null,null,3.07,null,2.17,null,null,null,null,null,null,null,null,null,null,null,null,null,3.39,null,3.79,null,null,null,6.48,null,null,6.23,null,null,null,5.67,null,6.4,null,null,null,5.75,null,null,null,3.25,null,null,null,null,null,null,null,null,null,null,2.51,null,null,null,null,null,null,null,3.79,null,2.92,null,null,null,2.77,null,3.22,null,null,null,6.29,null,null,5.83,null,6.35,null,null,null,null,null,null,null,5.94,null,6.19,6.38,null,null,5.68,null,null,null,5.76,null,3.15,null,null,null,null,3.07,null,2.17,null,null,null,null,null,null,null,null,null,null,null,null,null,3.39,null,3.79,null,null,null,6.48,null,null,6.23,null,null,null,5.67,null,6.4,null,null,null,5.75,null,null,null,3.25,null,null,null,null,null,3.43,4.16,5.97,null,null,2.62,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,2.94,null,6.36,null,null,5.63,null,null,null,null,null,null,null,null,6.35,null,5.73,null,null,null,6.1,5.61,null,null,null,null],[2.4,2.4,1.97,null,null,2.3,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1.72,null,1.85,null,null,1.82,null,null,null,null,null,null,null,null,2.14,null,1.86,null,null,null,2.07,1.94,null,null,null,null,2.2,null,null,null,null,2.09,null,1.59,null,null,null,null,null,null,null,null,null,null,null,null,null,2.31,null,2.69,null,null,null,1.94,null,null,2.03,null,null,null,2,null,2.06,null,null,null,1.92,null,null,null,2.2,null,null,null,null,null,null,null,null,null,null,2.22,null,null,null,null,null,null,null,2.47,null,1.86,null,null,null,1.82,null,2.12,null,null,null,2.04,null,null,2.06,null,1.97,null,null,null,null,null,null,null,1.93,null,1.86,2.1,null,null,2.13,null,null,null,2,null,2.2,null,null,null,null,2.09,null,1.59,null,null,null,null,null,null,null,null,null,null,null,null,null,2.31,null,2.69,null,null,null,1.94,null,null,2.03,null,null,null,2,null,2.06,null,null,null,1.92,null,null,null,2.2,null,null,null,null,null,2.4,2.4,1.97,null,null,2.3,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1.72,null,1.85,null,null,1.82,null,null,null,null,null,null,null,null,2.14,null,1.86,null,null,null,2.07,1.94,null,null,null,null],[13,14,13,11,10,13,18,1,11,19,9,6,5,6,10,12,4,17,3,19,19,10,5,19,7,1,16,10,9,16,5,1,17,17,18,18,6,8,14,2,15,2,6,9,14,16,8,2,4,10,13,18,10,9,18,16,19,7,20,9,10,6,2,6,2,3,5,10,1,10,3,15,2,13,6,6,2,7,9,8,7,1,19,8,13,5,15,1,1,10,13,3,11,9,14,19,4,4,17,6,8,4,1,2,1,13,6,1,17,20,20,5,8,13,19,7,11,2,20,7,19,15,4,6,20,13,4,10,13,10,13,18,6,17,17,17,9,10,13,20,16,15,3,2,13,10,10,9,16,5,13,18,10,9,18,16,19,7,20,9,10,6,2,6,2,3,5,10,1,10,3,15,2,13,6,6,2,7,9,8,7,1,19,8,13,5,15,1,1,10,13,3,11,9,14,19,4,4,17,6,13,14,13,11,10,13,18,1,11,19,9,6,5,6,10,12,4,17,3,19,19,10,5,19,7,1,16,10,9,16,5,1,17,17,18,18,6,8,14,2,15,2,6,9,14,16,8,2,4,10],[\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ONLY\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_UNSEEN_NEW\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_FAKE_a\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\",\"RET_SEEN\"],[\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Negative\",\"Neutral\",\"Neutral\",\"Neutral\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Negative\",\"Neutral\",\"Neutral\",\"Neutral\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\",\"Neutral\"]],\"container\":\"\\n \\n \\n  \\n Content\\n nr\\n valmn\\n valsd\\n aromn\\n arosd\\n dom1mn\\n dom1sd\\n dom2mn\\n dom2sd\\n set\\n Condition\\n Emotion\\n \\n \\n\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3,4,5,6,7,8,9,10,11]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\rVisual Distribution of Data\rinspect_cat(Task_Spreadsheet, show_plot = TRUE)\r## # A tibble: 3 x 5\r## col_name cnt common common_pcnt levels ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;named list\u0026gt; ## 1 Condition 5 ENC_ONLY 20 \u0026lt;tibble [5 x 3]\u0026gt; ## 2 Content 114 Mutilation 10.4 \u0026lt;tibble [114 x 3]\u0026gt;\r## 3 Emotion 2 Negative 50 \u0026lt;tibble [2 x 3]\u0026gt;\r\rChecks for image condition counts\rkable(Task_Spreadsheet %\u0026gt;% select(valmn, aromn, dom1mn, Emotion) %\u0026gt;% group_by(Emotion) %\u0026gt;% count(Emotion))\r\r\rEmotion\rn\r\r\r\rNegative\r125\r\rNeutral\r125\r\r\r\r#Check number of images for each type kable(Task_Spreadsheet %\u0026gt;% select(valmn, aromn, dom1mn, Condition) %\u0026gt;% group_by(Condition) %\u0026gt;% count(Condition))\r\r\rCondition\rn\r\r\r\rENC_ONLY\r50\r\rENC_ORIGINAL_b\r50\r\rRET_FAKE_a\r50\r\rRET_SEEN\r50\r\rRET_UNSEEN_NEW\r50\r\r\r\r\rDescriptives of pooled Means and SDs by Negative and Neutral Images.\r#Means and SDs\rkable(core_images_df %\u0026gt;% select(valmn, valsd, aromn, arosd, dom1mn, dom1sd, Emotion) %\u0026gt;% group_by(Emotion) %\u0026gt;% summarise(ValMean = mean(valmn)\r, Valsd = sd(valsd)\r, ArousMean = mean(aromn)\r, ArouSD = sd(arosd)\r, DomMean = mean(na.omit(dom1mn)\r, DomSD = sd(dom1sd)))) \r\r\rEmotion\rValMean\rValsd\rArousMean\rArouSD\rDomMean\r\r\r\rNegative\r2.226400\r0.3180505\r6.440667\r0.205209\r3.330000\r\rNeutral\r5.226667\r0.2736360\r2.909600\r0.207334\r5.997759\r\r\r\r\rScatterplot of all Images with mean scores\rp \u0026lt;- subplot(\rplot_ly(core_images_df, x = ~ Content, y = ~ aromn, type = \u0026quot;scatter\u0026quot;) %\u0026gt;% add_trace(y = ~ aromn) %\u0026gt;%\rlayout(yaxis = list(title = \u0026quot;Arousal\u0026quot;)),\rplot_ly(core_images_df, x = ~Content, y = ~ valmn, type = \u0026quot;scatter\u0026quot;) %\u0026gt;% add_trace(y = ~valmn) %\u0026gt;% layout(yaxis = list(title = \u0026quot;Valence\u0026quot;)),\rplot_ly(core_images_df, x = ~Content, y = ~ dom1mn, type = \u0026quot;scatter\u0026quot;) %\u0026gt;% add_trace(y = ~dom1mn) %\u0026gt;%\rlayout(yaxis = list(title = \u0026quot;Dominance\u0026quot;)),\rtitleY = TRUE, shareX = TRUE, nrows = 3\r) %\u0026gt;% hide_legend()\rp\r\r{\"x\":{\"data\":[{\"x\":[\"Parrots\",\"Gannet\",\"Grouper\",\"NeuWoman\",\"Fingerprint\",\"Girl\",\"Kiss\",\"Factoryworker\",\"Chess\",\"War\",\"NativeBoy\",\"DeerHead\",\"Mutilation\",\"Gold\",\"Mutilation\",\"Accident\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Injury\",\"DeadBody\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Stitches\",\"Surgery\",\"Surgery\",\"Tumor\",\"Attack\",\"Attack\",\"Rocks\",\"Satellite\",\"Field\",\"Farmland\",\"Field\",\"Nature\",\"Leaves\",\"Soldier\",\"Attack\",\"DeadTiger\",\"Attack\",\"Attack\",\"Gang\",\"Guns\",\"Police\",\"Police\",\"Buttons\",\"Disk\",\"GasCan\",\"Rubberbands\",\"Scissors\",\"Razor\",\"Video\",\"Fan\",\"Iron\",\"Shoes\",\"Mug\",\"Train\",\"Baskets\",\"Zipper\",\"HairDryer\",\"Clothespins\",\"Lightbulb\",\"Tool\",\"TrashCan\",\"FireHydrant\",\"Bus\",\"Umbrella\",\"Fabric\",\"Pole\",\"Rug\",\"AbstractArt\",\"AbstractArt\",\"Scarves\",\"ClothesRack\",\"Building\",\"Building\",\"Bridge\",\"Office\",\"Boxer\",\"PlaneCrash\",\"HurtDog\",\"InjuredDog\",\"Rain\",\"WarVictim\",\"DeadBody\",\"Vomit\",\"EmptyPool\",\"DeadMan\",\"Hanging\",\"Assault\",\"DeadMan\",\"Porpoises\",\"Skinhead\",\"KKKrally\",\"CarAccident\",\"CarAccident\",\"Fire\",\"AttackDog\",\"Woman\",\"Tourist\",\"Shadow\",\"HeadlessBody\",\"Mutilation\",\"Organs\",\"BurnVictim\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"BurnVictim\",\"BurnVictim\",\"Mutilation\",\"BabyTumor\",\"SeveredHand\",\"Boat\",\"Mushroom\",\"Plant\",\"Clouds\",\"Assault\",\"AimedGun\",\"BeatenFem\",\"Attack\",\"Suicide\",\"RollingPin\",\"Towel\",\"Spoon\",\"Bowl\",\"Mug\",\"Basket\",\"PicnicTable\",\"Hammer\",\"Shoes\",\"DustPan\",\"Barbells\",\"Fork\",\"Book\",\"Lamp\",\"Man\",\"Office\",\"Cabinet\",\"Tissue\",\"Fire\",\"Soldiers\",\"Dirty\",\"Soldier\",\"Execution\",\"Dog\"],\"y\":[3.17,2.83,3.29,2.94,3.71,2.9,4.99,2.93,2.79,6.21,6.8,5.97,7.26,4.84,7.16,5.9,6.76,6.41,6.77,7.03,7.22,6.06,6.84,6.97,6.61,6,6.36,6.57,6.82,5.75,6.99,6.82,2.51,3.26,3.03,2.79,3.55,3.14,2.51,6.01,6.44,6.2,6.96,6.59,6.29,6.21,6.28,5.8,3.2,3.07,3.81,3,3.25,3.4,3.12,2.17,2.99,2.03,2.66,3.29,2.6,3.32,2.75,3.01,3.02,3.07,2.55,2.89,2.92,2.61,3.07,2.98,2.88,2.3,4.28,2.93,2.43,2.39,3.26,3.18,2.95,5.91,6.36,6.58,6.45,3.08,6.6,6.64,6.24,2.63,6.72,6.81,5.92,5.89,5.82,6.05,6.62,6.08,6.63,6.52,6.51,3.24,3,2.96,6.64,5.82,6.3,6.91,6.48,5.78,6.35,6.86,6.49,6.7,6.55,7.21,6.91,2.88,3,2.59,3.1,6.06,7.35,6.38,7.09,6.24,2.42,3.16,2,2.33,3.01,1.76,2.63,3.06,3.01,2.69,4.02,2.32,2.61,1.72,3.39,3.95,2.65,2.28,6.46,6.53,6,7.07,6.49,6.14],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"color\":\"rgba(31,119,180,1)\",\"line\":{\"color\":\"rgba(31,119,180,1)\"}},\"error_y\":{\"color\":\"rgba(31,119,180,1)\"},\"error_x\":{\"color\":\"rgba(31,119,180,1)\"},\"line\":{\"color\":\"rgba(31,119,180,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null},{\"x\":[\"Parrots\",\"Gannet\",\"Grouper\",\"NeuWoman\",\"Fingerprint\",\"Girl\",\"Kiss\",\"Factoryworker\",\"Chess\",\"War\",\"NativeBoy\",\"DeerHead\",\"Mutilation\",\"Gold\",\"Mutilation\",\"Accident\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Injury\",\"DeadBody\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Stitches\",\"Surgery\",\"Surgery\",\"Tumor\",\"Attack\",\"Attack\",\"Rocks\",\"Satellite\",\"Field\",\"Farmland\",\"Field\",\"Nature\",\"Leaves\",\"Soldier\",\"Attack\",\"DeadTiger\",\"Attack\",\"Attack\",\"Gang\",\"Guns\",\"Police\",\"Police\",\"Buttons\",\"Disk\",\"GasCan\",\"Rubberbands\",\"Scissors\",\"Razor\",\"Video\",\"Fan\",\"Iron\",\"Shoes\",\"Mug\",\"Train\",\"Baskets\",\"Zipper\",\"HairDryer\",\"Clothespins\",\"Lightbulb\",\"Tool\",\"TrashCan\",\"FireHydrant\",\"Bus\",\"Umbrella\",\"Fabric\",\"Pole\",\"Rug\",\"AbstractArt\",\"AbstractArt\",\"Scarves\",\"ClothesRack\",\"Building\",\"Building\",\"Bridge\",\"Office\",\"Boxer\",\"PlaneCrash\",\"HurtDog\",\"InjuredDog\",\"Rain\",\"WarVictim\",\"DeadBody\",\"Vomit\",\"EmptyPool\",\"DeadMan\",\"Hanging\",\"Assault\",\"DeadMan\",\"Porpoises\",\"Skinhead\",\"KKKrally\",\"CarAccident\",\"CarAccident\",\"Fire\",\"AttackDog\",\"Woman\",\"Tourist\",\"Shadow\",\"HeadlessBody\",\"Mutilation\",\"Organs\",\"BurnVictim\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"BurnVictim\",\"BurnVictim\",\"Mutilation\",\"BabyTumor\",\"SeveredHand\",\"Boat\",\"Mushroom\",\"Plant\",\"Clouds\",\"Assault\",\"AimedGun\",\"BeatenFem\",\"Attack\",\"Suicide\",\"RollingPin\",\"Towel\",\"Spoon\",\"Bowl\",\"Mug\",\"Basket\",\"PicnicTable\",\"Hammer\",\"Shoes\",\"DustPan\",\"Barbells\",\"Fork\",\"Book\",\"Lamp\",\"Man\",\"Office\",\"Cabinet\",\"Tissue\",\"Fire\",\"Soldiers\",\"Dirty\",\"Soldier\",\"Execution\",\"Dog\"],\"y\":[3.17,2.83,3.29,2.94,3.71,2.9,4.99,2.93,2.79,6.21,6.8,5.97,7.26,4.84,7.16,5.9,6.76,6.41,6.77,7.03,7.22,6.06,6.84,6.97,6.61,6,6.36,6.57,6.82,5.75,6.99,6.82,2.51,3.26,3.03,2.79,3.55,3.14,2.51,6.01,6.44,6.2,6.96,6.59,6.29,6.21,6.28,5.8,3.2,3.07,3.81,3,3.25,3.4,3.12,2.17,2.99,2.03,2.66,3.29,2.6,3.32,2.75,3.01,3.02,3.07,2.55,2.89,2.92,2.61,3.07,2.98,2.88,2.3,4.28,2.93,2.43,2.39,3.26,3.18,2.95,5.91,6.36,6.58,6.45,3.08,6.6,6.64,6.24,2.63,6.72,6.81,5.92,5.89,5.82,6.05,6.62,6.08,6.63,6.52,6.51,3.24,3,2.96,6.64,5.82,6.3,6.91,6.48,5.78,6.35,6.86,6.49,6.7,6.55,7.21,6.91,2.88,3,2.59,3.1,6.06,7.35,6.38,7.09,6.24,2.42,3.16,2,2.33,3.01,1.76,2.63,3.06,3.01,2.69,4.02,2.32,2.61,1.72,3.39,3.95,2.65,2.28,6.46,6.53,6,7.07,6.49,6.14],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"color\":\"rgba(255,127,14,1)\",\"line\":{\"color\":\"rgba(255,127,14,1)\"}},\"error_y\":{\"color\":\"rgba(255,127,14,1)\"},\"error_x\":{\"color\":\"rgba(255,127,14,1)\"},\"line\":{\"color\":\"rgba(255,127,14,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null},{\"x\":[\"Parrots\",\"Gannet\",\"Grouper\",\"NeuWoman\",\"Fingerprint\",\"Girl\",\"Kiss\",\"Factoryworker\",\"Chess\",\"War\",\"NativeBoy\",\"DeerHead\",\"Mutilation\",\"Gold\",\"Mutilation\",\"Accident\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Injury\",\"DeadBody\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Stitches\",\"Surgery\",\"Surgery\",\"Tumor\",\"Attack\",\"Attack\",\"Rocks\",\"Satellite\",\"Field\",\"Farmland\",\"Field\",\"Nature\",\"Leaves\",\"Soldier\",\"Attack\",\"DeadTiger\",\"Attack\",\"Attack\",\"Gang\",\"Guns\",\"Police\",\"Police\",\"Buttons\",\"Disk\",\"GasCan\",\"Rubberbands\",\"Scissors\",\"Razor\",\"Video\",\"Fan\",\"Iron\",\"Shoes\",\"Mug\",\"Train\",\"Baskets\",\"Zipper\",\"HairDryer\",\"Clothespins\",\"Lightbulb\",\"Tool\",\"TrashCan\",\"FireHydrant\",\"Bus\",\"Umbrella\",\"Fabric\",\"Pole\",\"Rug\",\"AbstractArt\",\"AbstractArt\",\"Scarves\",\"ClothesRack\",\"Building\",\"Building\",\"Bridge\",\"Office\",\"Boxer\",\"PlaneCrash\",\"HurtDog\",\"InjuredDog\",\"Rain\",\"WarVictim\",\"DeadBody\",\"Vomit\",\"EmptyPool\",\"DeadMan\",\"Hanging\",\"Assault\",\"DeadMan\",\"Porpoises\",\"Skinhead\",\"KKKrally\",\"CarAccident\",\"CarAccident\",\"Fire\",\"AttackDog\",\"Woman\",\"Tourist\",\"Shadow\",\"HeadlessBody\",\"Mutilation\",\"Organs\",\"BurnVictim\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"BurnVictim\",\"BurnVictim\",\"Mutilation\",\"BabyTumor\",\"SeveredHand\",\"Boat\",\"Mushroom\",\"Plant\",\"Clouds\",\"Assault\",\"AimedGun\",\"BeatenFem\",\"Attack\",\"Suicide\",\"RollingPin\",\"Towel\",\"Spoon\",\"Bowl\",\"Mug\",\"Basket\",\"PicnicTable\",\"Hammer\",\"Shoes\",\"DustPan\",\"Barbells\",\"Fork\",\"Book\",\"Lamp\",\"Man\",\"Office\",\"Cabinet\",\"Tissue\",\"Fire\",\"Soldiers\",\"Dirty\",\"Soldier\",\"Execution\",\"Dog\"],\"y\":[6.11,6.37,6.71,5.09,4.06,6.17,6.94,4.87,5.71,2.62,2.45,2.76,1.45,5.98,1.71,1.52,1.91,1.45,1.8,1.7,1.48,2.07,1.56,1.58,1.51,1.56,2.06,2.79,2.96,1.82,2.21,1.8,4.45,5.21,6.62,6.31,7.09,6.6,6.36,2.19,2.7,2.21,2.46,1.94,2.38,2.82,2.91,2.45,5.32,5,4.52,4.98,5.15,4.76,5.18,4.97,4.69,4.52,4.98,5.93,4.99,4.97,4.93,5.33,4.9,5.07,4.43,5.24,5.5,4.72,5.02,4.98,5.06,5.07,5.5,5.56,4.82,4.82,5.33,5.21,4.25,2.95,2.43,1.69,1.81,4.53,2.57,1.98,2.81,4.03,1.83,1.76,2.67,1.84,2.42,2.04,2.09,2.39,2.34,2.04,3.09,5.8,5.22,5.18,1.62,1.9,2.99,1.31,1.81,1.87,1.49,1.88,1.6,1.79,2.26,1.46,2.35,5.59,5.42,5.21,6.78,2.21,2.37,2.31,2.73,2.19,5,4.97,5.04,4.88,4.93,4.94,5.38,4.95,4.82,4.69,5.55,5.27,5.19,4.87,5.35,5.27,4.77,4.94,2.73,2.1,2.26,1.51,2.06,1.68],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"color\":\"rgba(44,160,44,1)\",\"line\":{\"color\":\"rgba(44,160,44,1)\"}},\"error_y\":{\"color\":\"rgba(44,160,44,1)\"},\"error_x\":{\"color\":\"rgba(44,160,44,1)\"},\"line\":{\"color\":\"rgba(44,160,44,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y2\",\"frame\":null},{\"x\":[\"Parrots\",\"Gannet\",\"Grouper\",\"NeuWoman\",\"Fingerprint\",\"Girl\",\"Kiss\",\"Factoryworker\",\"Chess\",\"War\",\"NativeBoy\",\"DeerHead\",\"Mutilation\",\"Gold\",\"Mutilation\",\"Accident\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Injury\",\"DeadBody\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Stitches\",\"Surgery\",\"Surgery\",\"Tumor\",\"Attack\",\"Attack\",\"Rocks\",\"Satellite\",\"Field\",\"Farmland\",\"Field\",\"Nature\",\"Leaves\",\"Soldier\",\"Attack\",\"DeadTiger\",\"Attack\",\"Attack\",\"Gang\",\"Guns\",\"Police\",\"Police\",\"Buttons\",\"Disk\",\"GasCan\",\"Rubberbands\",\"Scissors\",\"Razor\",\"Video\",\"Fan\",\"Iron\",\"Shoes\",\"Mug\",\"Train\",\"Baskets\",\"Zipper\",\"HairDryer\",\"Clothespins\",\"Lightbulb\",\"Tool\",\"TrashCan\",\"FireHydrant\",\"Bus\",\"Umbrella\",\"Fabric\",\"Pole\",\"Rug\",\"AbstractArt\",\"AbstractArt\",\"Scarves\",\"ClothesRack\",\"Building\",\"Building\",\"Bridge\",\"Office\",\"Boxer\",\"PlaneCrash\",\"HurtDog\",\"InjuredDog\",\"Rain\",\"WarVictim\",\"DeadBody\",\"Vomit\",\"EmptyPool\",\"DeadMan\",\"Hanging\",\"Assault\",\"DeadMan\",\"Porpoises\",\"Skinhead\",\"KKKrally\",\"CarAccident\",\"CarAccident\",\"Fire\",\"AttackDog\",\"Woman\",\"Tourist\",\"Shadow\",\"HeadlessBody\",\"Mutilation\",\"Organs\",\"BurnVictim\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"BurnVictim\",\"BurnVictim\",\"Mutilation\",\"BabyTumor\",\"SeveredHand\",\"Boat\",\"Mushroom\",\"Plant\",\"Clouds\",\"Assault\",\"AimedGun\",\"BeatenFem\",\"Attack\",\"Suicide\",\"RollingPin\",\"Towel\",\"Spoon\",\"Bowl\",\"Mug\",\"Basket\",\"PicnicTable\",\"Hammer\",\"Shoes\",\"DustPan\",\"Barbells\",\"Fork\",\"Book\",\"Lamp\",\"Man\",\"Office\",\"Cabinet\",\"Tissue\",\"Fire\",\"Soldiers\",\"Dirty\",\"Soldier\",\"Execution\",\"Dog\"],\"y\":[6.11,6.37,6.71,5.09,4.06,6.17,6.94,4.87,5.71,2.62,2.45,2.76,1.45,5.98,1.71,1.52,1.91,1.45,1.8,1.7,1.48,2.07,1.56,1.58,1.51,1.56,2.06,2.79,2.96,1.82,2.21,1.8,4.45,5.21,6.62,6.31,7.09,6.6,6.36,2.19,2.7,2.21,2.46,1.94,2.38,2.82,2.91,2.45,5.32,5,4.52,4.98,5.15,4.76,5.18,4.97,4.69,4.52,4.98,5.93,4.99,4.97,4.93,5.33,4.9,5.07,4.43,5.24,5.5,4.72,5.02,4.98,5.06,5.07,5.5,5.56,4.82,4.82,5.33,5.21,4.25,2.95,2.43,1.69,1.81,4.53,2.57,1.98,2.81,4.03,1.83,1.76,2.67,1.84,2.42,2.04,2.09,2.39,2.34,2.04,3.09,5.8,5.22,5.18,1.62,1.9,2.99,1.31,1.81,1.87,1.49,1.88,1.6,1.79,2.26,1.46,2.35,5.59,5.42,5.21,6.78,2.21,2.37,2.31,2.73,2.19,5,4.97,5.04,4.88,4.93,4.94,5.38,4.95,4.82,4.69,5.55,5.27,5.19,4.87,5.35,5.27,4.77,4.94,2.73,2.1,2.26,1.51,2.06,1.68],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"color\":\"rgba(214,39,40,1)\",\"line\":{\"color\":\"rgba(214,39,40,1)\"}},\"error_y\":{\"color\":\"rgba(214,39,40,1)\"},\"error_x\":{\"color\":\"rgba(214,39,40,1)\"},\"line\":{\"color\":\"rgba(214,39,40,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y2\",\"frame\":null},{\"x\":[\"Gannet\",\"Grouper\",\"Fingerprint\",\"Girl\",\"Kiss\",\"Chess\",\"NativeBoy\",\"Mutilation\",\"Mutilation\",\"Accident\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Injury\",\"DeadBody\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Stitches\",\"Surgery\",\"Surgery\",\"Tumor\",\"Attack\",\"Attack\",\"Rocks\",\"Farmland\",\"Field\",\"Nature\",\"Leaves\",\"Soldier\",\"Attack\",\"Attack\",\"Attack\",\"Gang\",\"Guns\",\"Police\",\"Police\",\"Buttons\",\"Disk\",\"GasCan\",\"Rubberbands\",\"Scissors\",\"Razor\",\"Video\",\"Fan\",\"Iron\",\"Shoes\",\"Mug\",\"Zipper\",\"HairDryer\",\"TrashCan\",\"FireHydrant\",\"Bus\",\"Umbrella\",\"Fabric\",\"AbstractArt\",\"Scarves\",\"ClothesRack\",\"Building\",\"Building\",\"Office\",\"Boxer\",\"PlaneCrash\",\"HurtDog\",\"InjuredDog\",\"Rain\",\"WarVictim\",\"DeadBody\",\"Vomit\",\"EmptyPool\",\"DeadMan\",\"Hanging\",\"DeadMan\",\"Porpoises\",\"Skinhead\",\"KKKrally\",\"CarAccident\",\"CarAccident\",\"Fire\",\"Woman\",\"Tourist\",\"Shadow\",\"HeadlessBody\",\"Organs\",\"BurnVictim\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"BurnVictim\",\"BurnVictim\",\"Mutilation\",\"BabyTumor\",\"SeveredHand\",\"Boat\",\"Mushroom\",\"Plant\",\"Clouds\",\"AimedGun\",\"Attack\",\"Suicide\",\"RollingPin\",\"Towel\",\"Spoon\",\"Bowl\",\"Mug\",\"Basket\",\"PicnicTable\",\"Hammer\",\"DustPan\",\"Fork\",\"Book\",\"Lamp\",\"Office\",\"Cabinet\",\"Tissue\",\"Soldiers\",\"Dirty\",\"Soldier\",\"Execution\",\"Dog\"],\"y\":[6.75,6.44,4.46,6.66,6.32,5.88,3.94,2.99,2.88,2.84,3.69,2.63,2.85,3.37,3.32,3.46,2.73,3.24,3.55,4.07,3.92,3.57,2.4,2.81,5.84,5.58,6.23,6.82,5.72,3.45,3,2.81,2.88,3.29,3.67,3.9,3.79,5.82,6.02,4.99,6.06,6.21,5.74,5.93,6.16,5.73,6.14,6.39,6.28,5.82,5.85,5.92,5.45,5.55,5.8,6.1,6.39,6.25,5.93,5.17,5.13,4.05,3.27,2.96,3.17,4.55,3.73,2.92,3.9,5.34,3,2.75,3.37,3.42,4.92,3.95,3.4,2.79,3.57,6.1,5.87,6.01,2.66,4.25,2.33,2.88,3.73,2.7,3.28,3,3.04,3.39,2.7,3.65,6.33,6.45,6.27,5.2,2.15,3.01,4.03,6.14,6.25,6.74,6.18,6.33,6.7,6.19,6.48,5.46,7.04,6.65,6.47,5.22,6.39,6.3,3.04,4.12,2.81,3.11,3.37],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"color\":\"rgba(148,103,189,1)\",\"line\":{\"color\":\"rgba(148,103,189,1)\"}},\"error_y\":{\"color\":\"rgba(148,103,189,1)\"},\"error_x\":{\"color\":\"rgba(148,103,189,1)\"},\"line\":{\"color\":\"rgba(148,103,189,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y3\",\"frame\":null},{\"x\":[\"Gannet\",\"Grouper\",\"Fingerprint\",\"Girl\",\"Kiss\",\"Chess\",\"NativeBoy\",\"Mutilation\",\"Mutilation\",\"Accident\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Injury\",\"DeadBody\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Stitches\",\"Surgery\",\"Surgery\",\"Tumor\",\"Attack\",\"Attack\",\"Rocks\",\"Farmland\",\"Field\",\"Nature\",\"Leaves\",\"Soldier\",\"Attack\",\"Attack\",\"Attack\",\"Gang\",\"Guns\",\"Police\",\"Police\",\"Buttons\",\"Disk\",\"GasCan\",\"Rubberbands\",\"Scissors\",\"Razor\",\"Video\",\"Fan\",\"Iron\",\"Shoes\",\"Mug\",\"Zipper\",\"HairDryer\",\"TrashCan\",\"FireHydrant\",\"Bus\",\"Umbrella\",\"Fabric\",\"AbstractArt\",\"Scarves\",\"ClothesRack\",\"Building\",\"Building\",\"Office\",\"Boxer\",\"PlaneCrash\",\"HurtDog\",\"InjuredDog\",\"Rain\",\"WarVictim\",\"DeadBody\",\"Vomit\",\"EmptyPool\",\"DeadMan\",\"Hanging\",\"DeadMan\",\"Porpoises\",\"Skinhead\",\"KKKrally\",\"CarAccident\",\"CarAccident\",\"Fire\",\"Woman\",\"Tourist\",\"Shadow\",\"HeadlessBody\",\"Organs\",\"BurnVictim\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"BurnVictim\",\"BurnVictim\",\"Mutilation\",\"BabyTumor\",\"SeveredHand\",\"Boat\",\"Mushroom\",\"Plant\",\"Clouds\",\"AimedGun\",\"Attack\",\"Suicide\",\"RollingPin\",\"Towel\",\"Spoon\",\"Bowl\",\"Mug\",\"Basket\",\"PicnicTable\",\"Hammer\",\"DustPan\",\"Fork\",\"Book\",\"Lamp\",\"Office\",\"Cabinet\",\"Tissue\",\"Soldiers\",\"Dirty\",\"Soldier\",\"Execution\",\"Dog\"],\"y\":[6.75,6.44,4.46,6.66,6.32,5.88,3.94,2.99,2.88,2.84,3.69,2.63,2.85,3.37,3.32,3.46,2.73,3.24,3.55,4.07,3.92,3.57,2.4,2.81,5.84,5.58,6.23,6.82,5.72,3.45,3,2.81,2.88,3.29,3.67,3.9,3.79,5.82,6.02,4.99,6.06,6.21,5.74,5.93,6.16,5.73,6.14,6.39,6.28,5.82,5.85,5.92,5.45,5.55,5.8,6.1,6.39,6.25,5.93,5.17,5.13,4.05,3.27,2.96,3.17,4.55,3.73,2.92,3.9,5.34,3,2.75,3.37,3.42,4.92,3.95,3.4,2.79,3.57,6.1,5.87,6.01,2.66,4.25,2.33,2.88,3.73,2.7,3.28,3,3.04,3.39,2.7,3.65,6.33,6.45,6.27,5.2,2.15,3.01,4.03,6.14,6.25,6.74,6.18,6.33,6.7,6.19,6.48,5.46,7.04,6.65,6.47,5.22,6.39,6.3,3.04,4.12,2.81,3.11,3.37],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"color\":\"rgba(140,86,75,1)\",\"line\":{\"color\":\"rgba(140,86,75,1)\"}},\"error_y\":{\"color\":\"rgba(140,86,75,1)\"},\"error_x\":{\"color\":\"rgba(140,86,75,1)\"},\"line\":{\"color\":\"rgba(140,86,75,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y3\",\"frame\":null}],\"layout\":{\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"title\":\"Content\",\"type\":\"category\",\"categoryorder\":\"array\",\"categoryarray\":[\"AbstractArt\",\"Accident\",\"AimedGun\",\"Attack\",\"BabyTumor\",\"Basket\",\"Boat\",\"Book\",\"Bowl\",\"Boxer\",\"Building\",\"BurnVictim\",\"Bus\",\"Buttons\",\"Cabinet\",\"CarAccident\",\"Chess\",\"ClothesRack\",\"Clouds\",\"DeadBody\",\"DeadMan\",\"Dirty\",\"Disk\",\"Dog\",\"DustPan\",\"EmptyPool\",\"Execution\",\"Fabric\",\"Fan\",\"Farmland\",\"Field\",\"Fingerprint\",\"Fire\",\"FireHydrant\",\"Fork\",\"Gang\",\"Gannet\",\"GasCan\",\"Girl\",\"Grouper\",\"Guns\",\"HairDryer\",\"Hammer\",\"Hanging\",\"HeadlessBody\",\"HurtDog\",\"InjuredDog\",\"Injury\",\"Iron\",\"Kiss\",\"KKKrally\",\"Lamp\",\"Leaves\",\"Mug\",\"Mushroom\",\"Mutilation\",\"NativeBoy\",\"Nature\",\"Office\",\"Organs\",\"PicnicTable\",\"PlaneCrash\",\"Plant\",\"Police\",\"Porpoises\",\"Rain\",\"Razor\",\"Rocks\",\"RollingPin\",\"Rubberbands\",\"Scarves\",\"Scissors\",\"SeveredHand\",\"Shadow\",\"Shoes\",\"Skinhead\",\"Soldier\",\"Soldiers\",\"Spoon\",\"Stitches\",\"Suicide\",\"Surgery\",\"Tissue\",\"Tourist\",\"Towel\",\"TrashCan\",\"Tumor\",\"Umbrella\",\"Video\",\"Vomit\",\"WarVictim\",\"Woman\",\"Zipper\"],\"anchor\":\"y3\"},\"yaxis3\":{\"domain\":[0,0.313333333333333],\"automargin\":true,\"title\":\"Dominance\",\"anchor\":\"x\"},\"yaxis2\":{\"domain\":[0.353333333333333,0.646666666666667],\"automargin\":true,\"title\":\"Valence\",\"anchor\":\"x\"},\"yaxis\":{\"domain\":[0.686666666666667,1],\"automargin\":true,\"title\":\"Arousal\",\"anchor\":\"x\"},\"annotations\":[],\"shapes\":[],\"images\":[],\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"hovermode\":\"closest\",\"showlegend\":false},\"attrs\":{\"4cec6431346f\":{\"x\":{},\"y\":{},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter\"},\"4cec6431346f.1\":{\"x\":{},\"y\":{},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter\",\"inherit\":true},\"4cec3b02659a\":{\"x\":{},\"y\":{},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter\"},\"4cec3b02659a.1\":{\"x\":{},\"y\":{},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter\",\"inherit\":true},\"4cec547a4ad1\":{\"x\":{},\"y\":{},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter\"},\"4cec547a4ad1.1\":{\"x\":{},\"y\":{},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter\",\"inherit\":true}},\"source\":\"A\",\"config\":{\"showSendToCloud\":false},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"subplot\":true,\".hideLegend\":true,\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\r\rCurrently not rendering in Hugo\r\r\rUnvalidated Data\rFollowing are the image codes that for the pictures that are edited to look like thier fake counterparts that need approval from ethics.\nunapproved_IAPS_raw \u0026lt;- as.matrix(c(2036,3030,3069,3130,3530,6021,6838,7187,8485,\r2038,3059,3071,3131,5390,6212,7031,7491,9252,\r2320,3062,3080,3150,5500,6370,7035,7493,9425,\r2580,3063,3100,3268,5711,6510,7038,7500,9433,\r3010,3064,3103,3212,5725,6520,7039,7547,9904,\r3016,3068,3110,3500,5750,6550,7055,7700))\runapproved_images_df \u0026lt;- data.frame(unapproved_IAPS_raw) # convert to data frame\rkable(count(unapproved_images_df)) # check the number of images\r\r\rn\r\r\r\r53\r\r\r\r#Filter a new list with only new unapproved images\rnon_validated_iaps_all \u0026lt;- filter(group39_df, nr %in% unapproved_IAPS_raw)\r# filter for only negative images\rnon_validated_iaps \u0026lt;- filter(group39_df\r, nr %in% unapproved_IAPS_raw\r, Condition != \u0026quot;RET_PS_a\u0026quot;\r, Emotion == \u0026quot;Negative\u0026quot;) %\u0026gt;% arrange(nr)\rdatatable(non_validated_iaps, class = \u0026#39;cell-border stripe\u0026#39;, caption = \u0026#39;Unapproved Negative IAPS\u0026#39;)\r\r{\"x\":{\"filter\":\"none\",\"caption\":\"Unapproved Negative IAPS\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\"],[\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"BurnVictim\",\"Injury\",\"BurnVictim\",\"Mutilation\",\"Mutilation\",\"Mutilation\",\"Surgery\",\"Attack\",\"Attack\",\"Assault\",\"Soldier\",\"Attack\",\"Attack\",\"Attack\",\"Attack\",\"Police\",\"Fire\",\"DeadBody\",\"Assault\",\"DeadMan\",\"CarAccident\"],[3010,3016,3030,3059,3062,3063,3064,3068,3069,3071,3080,3100,3103,3110,3130,3131,3150,3212,3500,3530,6021,6212,6370,6510,6520,6550,6838,8485,9252,9425,9433,9904],[1.71,1.9,1.91,1.81,1.87,1.49,1.45,1.8,1.7,1.88,1.48,1.6,2.07,1.79,1.58,1.51,2.26,2.79,2.21,1.8,2.21,2.19,2.7,2.46,1.94,2.73,2.45,2.73,1.98,2.67,1.84,2.39],[1.19,1.31,1.56,1.24,1.31,0.96,0.97,1.56,1.41,1.39,0.95,1.07,1.27,1.3,1.24,0.97,1.57,1.67,1.34,1.32,1.51,1.49,1.52,1.58,1.27,2.38,1.44,1.62,1.59,1.44,1.19,1.36],[7.16,5.82,6.76,6.48,5.78,6.35,6.41,6.77,7.03,6.86,7.22,6.49,6.06,6.7,6.97,6.61,6.55,6.57,6.99,6.82,6.06,6.01,6.44,6.96,6.59,7.09,5.8,6.46,6.64,5.92,5.89,6.08],[2.24,2.44,2.1,2.32,2.57,2.6,2.62,2.49,2.41,2.05,1.97,2.23,2.3,2.16,2.07,2.34,2.2,1.99,2.19,2.09,2.38,2.44,2.19,2.09,2.08,1.98,2.09,2.1,2.33,2.13,2.6,2.06],[2.88,null,3.69,2.88,3.73,2.7,2.63,null,null,3.28,2.85,3,3.37,3.04,3.46,2.73,3.39,4.07,2.4,2.81,null,3.45,3,2.81,2.88,3.01,3.79,null,2.92,null,3.37,3.4],[2.41,null,2.1,2.1,2.5,2.02,2.04,null,null,2.15,2.1,2.16,2,1.97,2.07,1.93,2.15,2.25,1.88,1.97,null,2.1,1.87,2.12,2.16,2.41,2.08,null,2.28,null,2.16,2.21],[null,3.07,null,null,null,null,null,2.51,2.62,null,null,null,null,null,null,null,null,null,null,null,3.39,null,null,null,null,null,null,3.25,2.77,3.22,null,null],[null,2.09,null,null,null,null,null,2.22,2.3,null,null,null,null,null,null,null,null,null,null,null,2.31,null,null,null,null,null,null,2.2,1.82,2.12,null,null],[2,16,1,20,9,10,10,13,13,6,6,2,18,6,1,17,2,19,5,6,15,8,5,6,19,6,11,14,7,15,10,19],[\"ENC_RET_ORIG_UNSEEN\",\"ENC_ORIGINAL_b\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_ORIGINAL_b\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_ORIGINAL_b\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_ORIGINAL_b\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_ORIGINAL_b\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_ORIGINAL_b\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_ORIGINAL_b\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_ORIGINAL_b\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_ORIGINAL_b\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_RET_ORIG_UNSEEN\",\"ENC_RET_ORIG_UNSEEN\"],[\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\"]],\"container\":\"\\n \\n \\n  \\n Content\\n nr\\n valmn\\n valsd\\n aromn\\n arosd\\n dom1mn\\n dom1sd\\n dom2mn\\n dom2sd\\n set\\n Condition\\n Emotion\\n \\n \\n\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3,4,5,6,7,8,9,10,11]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\r","date":1563235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563254315,"objectID":"b0b155fbef938e68fffc20dad93f219a","permalink":"/post/emotional-impact-of-memory-part-one/","publishdate":"2019-07-16T00:00:00Z","relpermalink":"/post/emotional-impact-of-memory-part-one/","section":"post","summary":"Processing an image database for use in a experiment to induce an emotional state in particpants.\nResearch Protocol\rlibrary(tidyverse)\rlibrary(stringr)\rlibrary(knitr)\rlibrary(plotly)\rlibrary(gridExtra)\rlibrary(inspectdf)\rlibrary(DT)\rThe following was the code used to prepare images from the IAPS database for a experiment on pattern separation. The participants were seated in front of a PC and went through three tasks: Encoding, retreival and validation.","tags":["research"],"title":"Emotional Impact of Memory Part One ","type":"post"},{"authors":[],"categories":["R"],"content":"\rR Markdown\rImport dataset\rsuicide_raw \u0026lt;- read_csv(\u0026quot;data/master.csv\u0026quot;)\rsuicide_df \u0026lt;- suicide_raw %\u0026gt;% select(country\r, year\r, \u0026quot;No_of_Suicides\u0026quot; =`suicides_no`\r, \u0026quot;ave_suicide_100k\u0026quot; = `suicides/100k pop`\r, sex\r, age\r, population\r, \u0026quot;HDI\u0026quot; = `HDI for year`\r, \u0026quot;GDP_per_year\u0026quot; = `gdp_for_year ($)`\r, \u0026quot;GDP_per_capita\u0026quot; = `gdp_per_capita ($)`\r, generation)\r# converts to factors\rsuicide_df$sex \u0026lt;- factor(suicide_df$sex, levels = c(\u0026quot;male\u0026quot;, \u0026quot;female\u0026quot;))\rsuicide_df$year \u0026lt;- factor(suicide_df$year)\rsuicide_df$generation \u0026lt;- factor(suicide_df$generation)\rsuicide_df$country \u0026lt;- factor(suicide_df$country)\rsuicide_df$generation \u0026lt;- factor(suicide_df$generation, ordered = T, levels = c(\u0026quot;G.I. Generation\u0026quot;, \u0026quot;Silent\u0026quot;,\r\u0026quot;Boomers\u0026quot;, \u0026quot;Generation X\u0026quot;, \u0026quot;Millenials\u0026quot;, \u0026quot;Generation Z\u0026quot;))\r\rExplore dataset\rTake a look at the top 50 global number of suicides from 1985 to 2015 and split by sex.\n\rTotal Amount of Suicides from 1995 to 2015\rsuicide_df %\u0026gt;% group_by(country, sex) %\u0026gt;% summarise(Suicide_total = sum(No_of_Suicides)) %\u0026gt;% arrange(desc(Suicide_total)) %\u0026gt;% head(50) %\u0026gt;% ggplot(aes(x = reorder(country, -Suicide_total), y = Suicide_total)\r) +\rgeom_col(show.legend = FALSE, alpha = 0.7) +\rcoord_flip() +\rfacet_wrap(~sex) +\rlabs(x = \u0026quot;Country\u0026quot;, y = \u0026quot;Suicides 1995 to 2015\u0026quot;, title = \u0026quot;Total Number of Suicides from 1985 to 2015\u0026quot;) \rThe Russian Federation has had the most amount of people commit suicide between 1985 to 2015.\rFollowing this, United States and Japan have a high number of suicides with Males commiting suicide\rmore than Females.\nAverage suicide rate per population of 100,000\rave_suicide_100k_country \u0026lt;- suicide_df %\u0026gt;% group_by(country) %\u0026gt;% summarise(n = n(), Ave = mean(ave_suicide_100k)) %\u0026gt;% arrange(desc(Ave))\rave_suicide_100k_year \u0026lt;- suicide_df %\u0026gt;% group_by(country, year) %\u0026gt;% summarise(n = n(), Ave = mean(ave_suicide_100k)) %\u0026gt;% arrange(desc(Ave))\r# reorder the country ave_suicide_100k_country$country \u0026lt;- factor(ave_suicide_100k_country$country, ordered = T, levels = rev(ave_suicide_100k_country$country))\raverage_suicide_no \u0026lt;- (mean(ave_suicide_100k_country$Ave))\rave_suicide_100k_country %\u0026gt;% ggplot(aes(x = country, y = Ave)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + geom_hline(yintercept = average_suicide_no, linetype = 2, color = \u0026quot;grey35\u0026quot;, size = 1) +\rlabs(title = \u0026quot;Global suicides per 100k, by Country\u0026quot;,\rcaption = \u0026quot;1985 to 2015\u0026quot;,\rx = \u0026quot;Country\u0026quot;, y = \u0026quot;Suicides per 100k\u0026quot;) +\rcoord_flip() +\rscale_y_continuous(breaks = seq(0, 45, 2)) \r\rTotal Average Suicide Rate per Generation between 1985 to 2015\r\rGen Z, iGen, or Centennials: Born 1996  TBD\rMillennials or Gen Y: Born 1977  1995\rGeneration X: Born 1965  1976: 15 - 24 years\rBaby Boomers: Born 1946  1964\rTraditionalists or Silent Generation: Born 1945 and before\r\rave_suicide_100k_gen \u0026lt;- suicide_df %\u0026gt;% group_by(generation) %\u0026gt;% summarise(n = n(), Ave = sum(No_of_Suicides)) %\u0026gt;% arrange(desc(Ave))\rave_suicide_100k_gen$generation \u0026lt;- factor(ave_suicide_100k_gen$generation, ordered = T, levels = rev(ave_suicide_100k_gen$generation))\rggplot(data = ave_suicide_100k_gen) +\raes(x = generation, weight = Ave) +\rgeom_bar(fill = \u0026quot;#0c4c8a\u0026quot;) +\rlabs(title = \u0026quot;Total Suicides per Generation\u0026quot;,\rx = \u0026quot;Generation\u0026quot;,\ry = \u0026quot;Average Suicide Rate\u0026quot;,\rsubtitle = \u0026quot;1985 to 2015\u0026quot;) +\rtheme_bw() +\rcoord_flip()\r\rTotal Amount of Suicides per country by Age (1985 to 2015)\rx \u0026lt;- suicide_df %\u0026gt;% group_by(country, age) %\u0026gt;% summarise(total = sum(No_of_Suicides)) %\u0026gt;% filter(total \u0026gt; 2000) %\u0026gt;% arrange(desc(total))\rggplot(x, aes(x = reorder(country, - total), y = total, fill = age)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + labs(title = \u0026quot;Total Amount of Suicides per country by Age (1985 to 2015)\u0026quot;,\rsubtitle = \u0026quot;Filtered by Suicides greater than 2000\u0026quot;,\rx = \u0026quot;Country\u0026quot;, y = \u0026quot;Total Amount of Suicides\u0026quot;, fill = \u0026quot;age\u0026quot;) +\rcoord_flip() + theme(legend.position = \u0026quot;bottom\u0026quot;)\rAge group of 15 to 24 years has been a consistant marker for suicides. To Explore this further, we can look at\ra scatter plot ages over time. Will also remove the 5 to 14 years age group.\n# line graph by age group\rall_age_group \u0026lt;- suicide_df %\u0026gt;%\rgroup_by(year, age) %\u0026gt;% filter(!(age %in% \u0026quot;5-14 years\u0026quot;)) %\u0026gt;% filter(!(year %in% \u0026quot;2016\u0026quot;)) %\u0026gt;% #na.omit() %\u0026gt;% summarise(Num = sum(No_of_Suicides))\rggplot(all_age_group) +\raes(x = year, y = Num, fill = age, colour = age, group = age) +\rgeom_point(size = 2.2) +\rgeom_line() +\rlabs(x = \u0026quot;Year\u0026quot;, y = \u0026quot;Total Num Suicides\u0026quot;, title = \u0026quot;Total Suicides per Age Group\u0026quot;) +\rtheme_bw()+ theme(axis.text.x = element_text(angle = 90, hjust = 1))\r\rRegression model\rWe can use a regression model to see which age group is most likely to attempt suicide.\nmodel \u0026lt;- suicide_df %\u0026gt;% lm(No_of_Suicides ~ GDP_per_year + age + sex + generation, data = .) model %\u0026gt;% tidy(conf.int = TRUE) %\u0026gt;% filter(term != \u0026quot;(Intercept)\u0026quot;) %\u0026gt;%\rmutate(term = fct_reorder(term, estimate)) %\u0026gt;% # almost always remove this\rggplot(aes(estimate, term)) +\rgeom_point() +\rgeom_errorbarh(aes(xmin = conf.low, xmax = conf.high))\r# model %\u0026gt;% # augment(data = suicide_df) %\u0026gt;% # ggplot(aes(.fitted, No_of_Suicides)) +\r# geom_point(alpha = .1)\rtidy(anova(model)) %\u0026gt;% mutate(Unique = sumsq / sum(sumsq))\r## # A tibble: 5 x 7\r## term df sumsq meansq statistic p.value Unique\r## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 GDP_per_year 1 4187272638. 4187272638. 6777. 0. 0.185 ## 2 age 5 757335476. 151467095. 245. 3.76e-257 0.0335 ## 3 sex 1 473491889. 473491889. 766. 2.07e-166 0.0209 ## 4 generation 5 36328382. 7265676. 11.8 2.22e- 11 0.00160\r## 5 Residuals 27807 17181626084. 617889. NA NA 0.759\rA rough look at the effects supports previous assumptions that being male and aged between 35 - 54 years are at a higher risk of suicide. Although there might well be some collinearity between generation and age groups as these are essentially capturing similar items. I will also remove the 5 -14 year old age group as this doesnt seem to be adding anything to the model.\nmodel2 \u0026lt;- suicide_df %\u0026gt;% filter(!(age %in% \u0026quot;5-14 years\u0026quot;)) %\u0026gt;% lm(No_of_Suicides ~ GDP_per_year + age + sex, data = .) model2 %\u0026gt;% tidy(conf.int = TRUE) %\u0026gt;% filter(term != \u0026quot;(Intercept)\u0026quot;) %\u0026gt;%\rmutate(term = fct_reorder(term, estimate)) %\u0026gt;% # almost always remove this\rggplot(aes(estimate, term)) +\rgeom_point() +\rgeom_errorbarh(aes(xmin = conf.low, xmax = conf.high))\rtidy(anova(model2)) %\u0026gt;% mutate(Unique = sumsq / sum(sumsq))\r## # A tibble: 4 x 7\r## term df sumsq meansq statistic p.value Unique\r## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 GDP_per_year 1 4959288738. 4959288738. 7036. 0. 0.222 ## 2 age 4 460837808. 115209452. 163. 3.10e-138 0.0206\r## 3 sex 1 561837996. 561837996. 797. 1.87e-172 0.0252\r## 4 Residuals 23203 16354227025. 704832. NA NA 0.732\rInterestly, men aged between 35 - 54 years old have the strongest effect on the number of suicides followed by the 55 to 74 year old age group then young adults.\n\rTake a look at Suicide Rate in Australia\rau_model \u0026lt;- suicide_df %\u0026gt;% filter(country %in% \u0026quot;Australia\u0026quot;) %\u0026gt;% group_by(year, sex, age) %\u0026gt;% summarise(No_of_Suicides = sum(No_of_Suicides), GDP_per_year = mean(GDP_per_year))\rmodel2 \u0026lt;- au_model %\u0026gt;% filter(!(age %in% \u0026quot;5-14 years\u0026quot;)) %\u0026gt;% lm(No_of_Suicides ~ GDP_per_year + age + sex, data = .) model2 %\u0026gt;% tidy(conf.int = TRUE) %\u0026gt;% filter(term != \u0026quot;(Intercept)\u0026quot;) %\u0026gt;%\rmutate(term = fct_reorder(term, estimate)) %\u0026gt;% # almost always remove this\rggplot(aes(estimate, term)) +\rgeom_point() +\rgeom_errorbarh(aes(xmin = conf.low, xmax = conf.high))\rtidy(anova(model2)) %\u0026gt;% mutate(Unique = sumsq / sum(sumsq))\r## # A tibble: 4 x 7\r## term df sumsq meansq statistic p.value Unique\r## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 GDP_per_year 1 71814. 71814. 10.3 1.50e- 3 0.00630\r## 2 age 4 4108872. 1027218. 147. 9.14e-69 0.361 ## 3 sex 1 5167969. 5167969. 739. 4.05e-82 0.453 ## 4 Residuals 293 2047900. 6989. NA NA 0.180\rSimilar pattern in Australia. Men aged 35 - 54 years old have the highest suicide rate.\nage_group_35_54 \u0026lt;- suicide_df %\u0026gt;% group_by(country, year, age) %\u0026gt;% filter(age %in% \u0026quot;35-54 years\u0026quot;) %\u0026gt;% summarise(Num = sum(No_of_Suicides))\rage_group_35_54 %\u0026gt;% filter(country %in% \u0026quot;Australia\u0026quot;) %\u0026gt;% ggplot() +\raes(x = year, y = Num) +\rgeom_point(size = 2, colour = \u0026quot;#0c4c8a\u0026quot;) +\rgeom_line() +\rlabs(title = \u0026quot;Total Suicides in Australia 1985 to 2015\u0026quot;, subtitle = \u0026quot;Age Group 35 to 54 Years Old\u0026quot;,\rx = \u0026quot;Year\u0026quot;,\ry = \u0026quot;Number of Suicides\u0026quot;) +\rtheme(axis.text.x = element_text(angle = 90, hjust = 1))\r\r\r\r","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559412213,"objectID":"ff04c2291204641c2d806686ceae6428","permalink":"/post/global-suicides-1995-to-2015/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/post/global-suicides-1995-to-2015/","section":"post","summary":"R Markdown\rImport dataset\rsuicide_raw \u0026lt;- read_csv(\u0026quot;data/master.csv\u0026quot;)\rsuicide_df \u0026lt;- suicide_raw %\u0026gt;% select(country\r, year\r, \u0026quot;No_of_Suicides\u0026quot; =`suicides_no`\r, \u0026quot;ave_suicide_100k\u0026quot; = `suicides/100k pop`\r, sex\r, age\r, population\r, \u0026quot;HDI\u0026quot; = `HDI for year`\r, \u0026quot;GDP_per_year\u0026quot; = `gdp_for_year ($)`\r, \u0026quot;GDP_per_capita\u0026quot; = `gdp_per_capita ($)`\r, generation)\r# converts to factors\rsuicide_df$sex \u0026lt;- factor(suicide_df$sex, levels = c(\u0026quot;male\u0026quot;, \u0026quot;female\u0026quot;))\rsuicide_df$year \u0026lt;- factor(suicide_df$year)\rsuicide_df$generation \u0026lt;- factor(suicide_df$generation)\rsuicide_df$country \u0026lt;- factor(suicide_df$country)\rsuicide_df$generation \u0026lt;- factor(suicide_df$generation, ordered = T, levels = c(\u0026quot;G.","tags":["R Markdown"],"title":"Global Suicides 1995 to 2015","type":"post"},{"authors":[],"categories":["R"],"content":"\rDoes reasoning about personal problems improve with psychological distance?\rSTUDY DESCRIPTION\rSolomons paradox describes the tendency for people to reason more wisely about other peoples\rproblems compared to their own. One potential explanation for this paradox is that people tend to view\rother peoples problems from a more psychologically distant perspective, whereas they view their own\rproblems from a psychologically immersed perspective . For example, imagine two friends, Beth and Zoe,\rare discussing Zoes relationship problems. Beths distance allows her to see that Zoes relationship is\rdoomed, so she can offer her friend sage advice for how to proceed with her relationship. Zoes\rimmersion in her own relationship may lead her to have a hard time reasoning wisely, because she may be\rworried that she will need to find a new apartment if she breaks up with her boyfriend.\nWhat if, however, Zoe was able to take a more psychologically distanced perspective when contemplating\rher relationship problems? Would she exhibit a higher level of wisdom, similar to what Beth was able to\rshow? To test this possibility, Grossmann and Kross (2014) asked romantically-involved participants to\rthink about a situation in which their partner cheated on them ( self condition ) or a friends partner\rcheated on their friend ( other condition ). Participants were also instructed to take a first-person\rperspective ( immersed condition ) by using pronouns such as I and me, or a third-person perspective\r( distanced condition ) by using pronouns such as he and her.\nParticipants were 120 university students who were involved in monogamous, heterosexual romantic\rrelationships, and participants were randomly assigned to condition. After contemplating the infidelity\rscenario described above with the assigned perspective, participants responded to various questions\rdesigned to assess wise reasoning.\nGrossmann, I., \u0026amp; Kross, E. (2014). Exploring Solomons paradox: Self-distancing eliminates self-other asymmetry in wise reasoning about close relationships in younger and older adults. Psychological Science, 25, 1571-1580.\n\rGiven the context of this study, a dimension that could have been explored more was that of how wisdom differs\rto that of intelligence. In that inteliigence is more applied and wisdom is the ability to learn from an experience.\n\r\rANAYSIS\rOpen the data file (called Grossmann and Kross 2014 Study 2). Explore the data file. Note, you\rwill not analyze all of these variables. Try to find the variables that are relevant to the study\rdescription above.\r\rlibrary(car)\rlibrary(dplyr)\rlibrary(psych)\rlibrary(ggplot2)\rlibrary(knitr)\rlibrary(pander)\rPsych_dist_df \u0026lt;- read.csv(\u0026quot;data/Grossman and Kross 2014 Study 2.csv\u0026quot;)\rConduct a one-way ANOVA to determine if there is a significant difference between the\rconditions on wisdom.\r\rConditions:\rDV: Wise Reasoning\n# Use the names() function to print out the list of variable names\r#names(Psych_dist_df)\r# We are interested in the conditions and wisdom variables\r# so we can use dplyr to select these and print a table to look at\r# Can see some NA cases\r#complete.cases(Psych_dist_df)\rdf \u0026lt;- Psych_dist_df[complete.cases(Psych_dist_df), ] # remove cases with NA and subset to new dataframe\rdf \u0026lt;- select(df, CONDITION, WISDOM) # filter out other variables and only use ones of interest\r\rDescriptives\rDescriptives \u0026lt;- select(df, CONDITION, WISDOM) %\u0026gt;% group_by(CONDITION) %\u0026gt;% summarise(count = n()\r,mean = mean(WISDOM)\r,sd = sd(WISDOM))\r# viewing the dataframe shows that the CONDITION is currently treated as an INT so we will # convert this to a factor with label names for clarity\rdf$CONDITION \u0026lt;- factor(df$CONDITION, labels = c(\u0026quot;Self_immersed\u0026quot;, \u0026quot;Self_dist\u0026quot;, \u0026quot;other_immersed\u0026quot;, \u0026quot;other_dist\u0026quot;) ) # convert the CONDITION int to a factor\rggplot(data = df) +\raes(x = CONDITION, y = WISDOM) +\rgeom_boxplot(fill = \u0026quot;#26828e\u0026quot;) +\rlabs(title = \u0026quot;Solomons paradox\u0026quot;,\rx = \u0026quot;Condition\u0026quot;,\ry = \u0026quot;Wisdom\u0026quot;,\rsubtitle = \u0026quot;Subtitle\u0026quot;) +\rtheme_bw()\rkable(Descriptives) %\u0026gt;% kableExtra::kable_styling()\r\r\rCONDITION\rcount\rmean\rsd\r\r\r\r1\r31\r-0.5593042\r1.1660305\r\r2\r26\r0.1220847\r0.9418065\r\r3\r33\r0.1948435\r0.7711439\r\r4\r25\r0.3344884\r0.8129734\r\r\r\r\rVisual Analysis\r\rRun ANOVA\ranova_model \u0026lt;- lm(WISDOM ~ CONDITION, data = df) #run an anova or lm\r\rRun the model through a Anova function\rpander(Anova(anova_model, type=\u0026quot;III\u0026quot;)) # Ue the car package to run the anova\rAnova Table (Type III tests)\r\r\r\r\rSum Sq\rDf\rF value\rPr(\u0026gt;F)\r\r\r\r(Intercept)\r9.697\r1\r11\r0.001232\r\rCONDITION\r14.13\r3\r5.343\r0.001783\r\rResiduals\r97.86\r111\rNA\rNA\r\r\r\r\rLevenes Test\rpander(leveneTest(anova_model)) # tests of homogeniety\rLevenes Test for Homogeneity of Variance (center = median)\r\r\r\r\rDf\rF value\rPr(\u0026gt;F)\r\r\r\rgroup\r3\r3.581\r0.01619\r\r\r111\rNA\rNA\r\r\r\r\rUsing the lm() function from earlier, printing the summary results in contrasts.\rpander(summary(anova_model)) # summary.lm gives us each level of the condition\r\r\r\r\r\rEstimate\rStd. Error\rt value\rPr(\u0026gt;|t|)\r\r\r\r(Intercept)\r-0.5593\r0.1686\r-3.317\r0.001232\r\rCONDITIONSelf_dist\r0.6814\r0.2497\r2.729\r0.00739\r\rCONDITIONother_immersed\r0.7541\r0.2348\r3.211\r0.001729\r\rCONDITIONother_dist\r0.8938\r0.2524\r3.541\r0.0005833\r\r\r\rFitting linear model: WISDOM ~ CONDITION\r\r\r\rObservations\rResidual Std. Error\r\\(R^2\\)\rAdjusted \\(R^2\\)\r\r\r\r115\r0.9389\r0.1262\r0.1026\r\r\r\r\rBox plot\rggplot(data = df , aes(x = CONDITION, y = WISDOM, colour = CONDITION)) + geom_boxplot(outlier.colour=\u0026quot;red\u0026quot; # the geom_ must be on the same line\r, outlier.shape=16\r, outlier.size=2\r, notch=TRUE) \rNext, you want to determine whether the self-immersed condition was significantly lower in\rwisdom, relative to the other-immersed and other-distanced condition. Conduct a planned\rcontrast to test the typical Solomons paradox effect.\r\r# planned contrasts\rc1 \u0026lt;- c(2, 0, -1, -1)\rplanned_contrasts \u0026lt;-c1\rcontrasts(df$CONDITION) \u0026lt;- planned_contrasts\rmodel1 \u0026lt;- aov(WISDOM ~ CONDITION, data = df)\rAnova(model1, type = \u0026quot;III\u0026quot;)\r## Anova Table (Type III tests)\r## ## Response: WISDOM\r## Sum Sq Df F value Pr(\u0026gt;F) ## (Intercept) 0.060 1 0.0682 0.794390 ## CONDITION 14.131 3 5.3432 0.001783 **\r## Residuals 97.855 111 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rsummary.aov(model1, split = list(CONDITION = list(\u0026quot;Self_immersed\u0026quot; = 1, \u0026quot;Self_dist\u0026quot; = 2, \u0026quot;other_immersed\u0026quot; = 3, \u0026quot;other_dist\u0026quot; = 4)))\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## CONDITION 3 14.13 4.710 5.343 0.00178 ** ## CONDITION: Self_immersed 1 13.47 13.468 15.277 0.00016 ***\r## CONDITION: Self_dist 1 0.66 0.660 0.749 0.38875 ## CONDITION: other_immersed 1 0.00 0.003 0.004 0.95210 ## CONDITION: other_dist 1 ## Residuals 111 97.86 0.882 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rNow, you want to show that taking a distant perspective increases wisdom relative to taking an\rimmersed perspective when dealing with ones own problems. Conduct a planned contrast to\rdetermine whether self-distancing results in significantly higher levels of wisdom, relative to\rself-immersion.\r\rc2 \u0026lt;- c(1, -1, 0, 0) # self distance vs self immursion\rplanned_contrasts \u0026lt;-c2\rcontrasts(df$CONDITION) \u0026lt;- planned_contrasts\rmodel2 \u0026lt;- aov(WISDOM ~ CONDITION, data = df)\rAnova(model2, type = \u0026quot;III\u0026quot;)\r## Anova Table (Type III tests)\r## ## Response: WISDOM\r## Sum Sq Df F value Pr(\u0026gt;F) ## (Intercept) 0.060 1 0.0682 0.794390 ## CONDITION 14.131 3 5.3432 0.001783 **\r## Residuals 97.855 111 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rsummary.aov(model2, split = list(CONDITION = list(\u0026quot;Self_immersed\u0026quot; = 1, \u0026quot;Self_dist\u0026quot; = 2, \u0026quot;other_immersed\u0026quot; = 3, \u0026quot;other_dist\u0026quot; = 4)))\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## CONDITION 3 14.13 4.710 5.343 0.00178 **\r## CONDITION: Self_immersed 1 7.43 7.430 8.428 0.00446 **\r## CONDITION: Self_dist 1 2.32 2.317 2.629 0.10780 ## CONDITION: other_immersed 1 4.38 4.384 4.973 0.02775 * ## CONDITION: other_dist 1 ## Residuals 111 97.86 0.882 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rYou also want to determine whether distancing vs.immersion increases wisdom when\rcontemplating other peoples problems. Conduct a planned contrast to compare the\rother-distance vs.other-immersed conditions.\r\rc3 \u0026lt;- c(0, 0, 1, -1) # other immersed vs other distance\rplanned_contrasts \u0026lt;-c3\rcontrasts(df$CONDITION) \u0026lt;- planned_contrasts\rmodel3 \u0026lt;- aov(WISDOM ~ CONDITION, data = df)\rAnova(model3, type = \u0026quot;III\u0026quot;)\r## Anova Table (Type III tests)\r## ## Response: WISDOM\r## Sum Sq Df F value Pr(\u0026gt;F) ## (Intercept) 0.060 1 0.0682 0.794390 ## CONDITION 14.131 3 5.3432 0.001783 **\r## Residuals 97.855 111 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rsummary.aov(model3, split = list(CONDITION = list(\u0026quot;Self_immersed\u0026quot; = 1, \u0026quot;Self_dist\u0026quot; = 2, \u0026quot;other_immersed\u0026quot; = 3, \u0026quot;other_dist\u0026quot; = 4)))\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## CONDITION 3 14.13 4.710 5.343 0.001783 ** ## CONDITION: Self_immersed 1 0.07 0.068 0.077 0.781773 ## CONDITION: Self_dist 1 1.77 1.769 2.007 0.159391 ## CONDITION: other_immersed 1 12.29 12.294 13.946 0.000299 ***\r## CONDITION: other_dist 1 ## Residuals 111 97.86 0.882 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rFinally, you want to test whether self-distancing eliminates the increased wisdom typically found\rin reasoning about others. Conduct a planned comparison to determine whether the\rself-distanced condition is significantly different from the other-immersed and other-distanced\rconditions.\r\rc4 \u0026lt;- c(0, 2, -1, -1) # self dist vs other immersed \u0026amp; other dist\rplanned_contrasts \u0026lt;-c4\rcontrasts(df$CONDITION) \u0026lt;- planned_contrasts\rmodel4 \u0026lt;- aov(WISDOM ~ CONDITION, data = df)\rAnova(model4, type = \u0026quot;III\u0026quot;)\r## Anova Table (Type III tests)\r## ## Response: WISDOM\r## Sum Sq Df F value Pr(\u0026gt;F) ## (Intercept) 0.060 1 0.0682 0.794390 ## CONDITION 14.131 3 5.3432 0.001783 **\r## Residuals 97.855 111 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rsummary.aov(model4, split = list(CONDITION = list(\u0026quot;Self_immersed\u0026quot; = 1, \u0026quot;Self_dist\u0026quot; = 2, \u0026quot;other_immersed\u0026quot; = 3, \u0026quot;other_dist\u0026quot; = 4)))\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## CONDITION 3 14.13 4.710 5.343 0.00178 **\r## CONDITION: Self_immersed 1 0.44 0.438 0.496 0.48260 ## CONDITION: Self_dist 1 5.48 5.476 6.212 0.01417 * ## CONDITION: other_immersed 1 8.22 8.218 9.322 0.00283 **\r## CONDITION: other_dist 1 ## Residuals 111 97.86 0.882 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rPrepare an APA-style results section to describe each of the analyses conducted above.\n\rGenerate a bar graph to depict the results for the one-way ANOVA. Dont forget to include error\rbars that reflect the +/- 1 standard error of the mean.\n\r\rggplot(df, aes(CONDITION, WISDOM))+\rstat_boxplot( aes(CONDITION, WISDOM), geom=\u0026#39;errorbar\u0026#39;, linetype=1, width=0.5)+ #whiskers\rgeom_boxplot( aes(CONDITION, WISDOM),outlier.shape=1) + stat_summary(fun.y=mean, geom=\u0026quot;point\u0026quot;, size=2) + stat_summary(fun.data = mean_se, geom = \u0026quot;errorbar\u0026quot;)\r\r\r","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559413258,"objectID":"e03199f9a4bd3b108a715fc5f42614d9","permalink":"/post/osl-workshop-solomons-paradox/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/post/osl-workshop-solomons-paradox/","section":"post","summary":"Does reasoning about personal problems improve with psychological distance?\rSTUDY DESCRIPTION\rSolomons paradox describes the tendency for people to reason more wisely about other peoples\rproblems compared to their own. One potential explanation for this paradox is that people tend to view\rother peoples problems from a more psychologically distant perspective, whereas they view their own\rproblems from a psychologically immersed perspective . For example, imagine two friends, Beth and Zoe,\rare discussing Zoes relationship problems.","tags":["Academic","R Markdown","Workshop"],"title":"OSL Workshop Solomons Paradox","type":"post"},{"authors":["Aaron Willcox"],"categories":null,"content":" Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Aaron Willcox","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":null,"categories":["R"],"content":"\rR Markdown\rThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars)\r## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00\rfit \u0026lt;- lm(dist ~ speed, data = cars)\rfit\r## ## Call:\r## lm(formula = dist ~ speed, data = cars)\r## ## Coefficients:\r## (Intercept) speed ## -17.579 3.932\r\rIncluding Plots\rYou can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1))\rpie(\rc(280, 60, 20),\rc(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;),\rcol = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;),\rinit.angle = -50, border = NA\r)\r\rFigure 1: A fancy pie chart.\r\r\r","date":1437703994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437703994,"objectID":"10065deaa3098b0da91b78b48d0efc71","permalink":"/post/2015-07-23-r-rmarkdown/","publishdate":"2015-07-23T21:13:14-05:00","relpermalink":"/post/2015-07-23-r-rmarkdown/","section":"post","summary":"R Markdown\rThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars)\r## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.","tags":["R Markdown","plot","regression"],"title":"Hello R Markdown","type":"post"},{"authors":["Aaron Willcox","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"}]